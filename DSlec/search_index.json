[["index.html", "データ分析入門 chapter: 1 イントロダクション 1.1 講義の概要 1.2 履修上の注意点 1.3 成績評価の基準および方法 1.4 授業計画 1.5 謝辞", " データ分析入門 山本 雅資 2022-09-17 このページは「データ分析入門A」(火曜日２限)およびB(金曜日2限)で使うコンテンツをまとめたものです。履修希望者は、AとBの両方を同時履修することをお勧めします。 chapter: 1 イントロダクション 1.1 講義の概要 本講義では、Rというプログラミング言語を用いて、社会・経済関連のデータについて、初歩的な分析することができるようになることを目指します。ビジネスにおける活用を例としたR言語の紹介については以下のリンクを参考にしてください。 日経クロステック (2020)「統計解析に便利、R言語の基本を実践で理解する」 Rは無料で提供されており、RStudioと呼ばれるインターフェースと同時に用いることで初心者にも比較的直感的に利用できる非常に優れた分析ツールです。講義では、プログラミングが初めての学生を想定して、Rのインストールから丁寧に行います。その上で、データの集計方法、グラフ、地図等による可視化、統計的仮説検定などを実行する方法を学びます。 1.2 履修上の注意点 講義の性質上、30人程度の履修制限を設ける場合があります。その場合、火曜２限と金曜２限をセット履修できる学生を優先します。また、履修者は以下の条件をすべて満たしていることが必要です。 講義にノートパソコンを持ってくることができる（Mac or Windows) 情報処理Iの単位を取得済みである 1.3 成績評価の基準および方法 講義内演習での理解度 (70%)及び最終課題 (30%)で評価します。 1.4 授業計画 詳細はシラバスを参照してください。 講義での進捗・理解度に応じて、内容は変更する可能性があります。 1.5 謝辞 このページの作成にあたっては多くのウェブサイトや先人の皆様のウェブ・SNSでのやりとりなどを参考にさせていただきました。たくさんありすぎてここに列挙することはできませんが、心より感謝申し上げます。 "],["chapter02.html", "chapter: 2 R及びRStudioのインストール 2.1 インストールを始める前に 2.2 Rのインストール 2.3 RStudioのインストール", " chapter: 2 R及びRStudioのインストール 2.1 インストールを始める前に 思いつく順にいくつか注意点をまとめてみました。 プログラミングを始めるということは、マウスをあまり使わない世界に足を踏み入れること。 一つ一つの作業が文字として残るので、作業の再現性が高まります。 クリックして探していたファイルを「パス(path)」という「住所」を示すことでパソコンに伝えることになります。 全角入力(日本語入力：原則コメント欄のみ)と半角入力(英数字入力)の違いをいつも意識する。 １２３４５は全角文字です。 12345は半角文字です。 1と１は区別がつきにくいですが、全角文字はプログラミングコードには使用できません。 変数やフォルダの名前をつける際に、スペースを入れることはトラブルのもとなのでなるべくスペースを含む名前はつけない。 ちなみに、スペースの半角と全角は肉眼ではまず区別できません。 Rは大文字と小文字を区別する言語（プログラミング言語によっては区別しないものもある）。 頻出する「フォルダ」と「ディレクトリ」は、ほぼ同じ意味と考えて良い。 Rはインターネットアクセスのあるところで利用することでその真価を発揮できる。 学内の無線LANにはすぐにアクセスできる状態にしておきましょう。 2.2 Rのインストール Rを利用する上で最大の難関がRのインストールです。幸い、高知工科大学の矢内勇生先生が大変わかりやすいインストールガイドを作成してくださっています。自分の使っているマシンに応じて以下のいずれかの資料を参照してインストールを進めましょう。 Windows用のインストールガイド Mac用のインストールガイド Rのインストールは環境によっては非常に簡単です。本講義の学生にとって、矢内先生のマニュアルに沿ってインストールすることが重要なのは、多くの学生が日本語版のウィンドウズかMacOSを使用しているためです。Rが利用するディレクトリなどに、半角英数以外の名前(日本語など）が使用されていると大きな問題を引き起こすことがあります。 上記のインストールガイドに書いてあることを順番に一つずつ実行すれば必ず成功します。ただし、以下はガイドのうち、とばしてもらっても大丈夫なものです。 ウィンドウズユーザー プログラミング用のフォントの話題 Rtoolsのインストール RStudioのカスタマイズ Macユーザー RStudioのカスタマイズ この作業にはダウンロードなども含めて大変時間がかかります。2回分の講義時間をとってありますので、じっくり腰を据えておこないましょう。 2.3 RStudioのインストール こちらはRのインストールに比べるとかなり楽に行うことができます。必ず先にR本体をインストールしてから、RStudioをインストールしてください。 Windows版のガイドでは、P82からがRStudioのインストールガイドです。 MacOS版のガイドでは、P34からがRStudioのインストールガイドです。 "],["chapter03.html", "chapter: 3 Rを使ってみよう：四則演算から外部データの読み込みまで 3.1 基本的な計算 3.2 変数の定義 3.3 データフレーム 3.4 データの型 3.5 パッケージの考え方 3.6 外部ファイルの読み込み 3.7 描画系のpackageの例", " chapter: 3 Rを使ってみよう：四則演算から外部データの読み込みまで 3.1 基本的な計算 計算してみよう # 足し算・引き算 1+1 ## [1] 2 3-1 ## [1] 2 150-121 ## [1] 29 # 記号「*」は掛け算を意味する 2*2 ## [1] 4 # 割り算は「/」を用いる 10/5 ## [1] 2 # 「^」はべき乗を意味する。 3^2 ## [1] 9 3^3 ## [1] 27 3^4 ## [1] 81 # 「sqrt」で平方根が計算できる。 sqrt(100) ## [1] 10 sqrt(25) ## [1] 5 sqrt(8) ## [1] 2.828427 sqrt(2) ## [1] 1.414214 3.2 変数の定義 # 「&lt;-」は代入操作を意味する x&lt;-4 2*x ## [1] 8 # ベクトルを代入 x&lt;-1:10 print(x) ## [1] 1 2 3 4 5 6 7 8 9 10 # seq(a,b,c)：aからbまでをc刻みで生成 y&lt;-seq(1,10,1) print(y) ## [1] 1 2 3 4 5 6 7 8 9 10 z&lt;-seq(1,10,2) print(z) ## [1] 1 3 5 7 9 # 文字列の扱い my_words&lt;-c(&quot;Good morning&quot;, &quot;Good afternoon&quot;, &quot;Good evening&quot;) print(my_words) ## [1] &quot;Good morning&quot; &quot;Good afternoon&quot; &quot;Good evening&quot; First&lt;-&quot;Good&quot; Second&lt;-c(&quot;mornig&quot;, &quot;afternoon&quot;, &quot;evening&quot;) # デフォルトでは、スペースで接続 First_Second&lt;-paste(First, Second) print(First_Second) ## [1] &quot;Good mornig&quot; &quot;Good afternoon&quot; &quot;Good evening&quot; # 接続の記号を変更 FSplus&lt;-paste(First, Second,sep=&quot;+&quot;) print(FSplus) ## [1] &quot;Good+mornig&quot; &quot;Good+afternoon&quot; &quot;Good+evening&quot; 3.3 データフレーム 上の例では、c()を使って、ベクトルとしてデータを扱う方法を確認しました。実際の分析では、ベクトルをいくつか集めたデータフレームを使って実証分析を行うことがほとんどです。以下では、ベクトルからデータフレームを作成する方法を示します。ただし、実際の分析では、ほとんどの場合、外部データ（行政が提供するエクセルファイルなど）から直接データフレームとして読み込みます。 # 日本の都道府県には固有の番号がある。 prefcode&lt;-c(1, 2,3,4,5,6,7, 8,9,10,11,12,13,14, 15,16,17,18, 19,20,21,22,23, 24,25,26,27,28,29,30, 31,32,33,34,35, 36,37,38,39, 40,41,42,43,44,45,46, 47) prefnameJ&lt;-c(&quot;01北海道&quot;, &quot;02青森県&quot;,&quot;03岩手県&quot;,&quot;04宮城県&quot;,&quot;05秋田県&quot;, &quot;06山形県&quot;,&quot;07福島県&quot;, &quot;08茨城県&quot;,&quot;09栃木県&quot;,&quot;10群馬県&quot;,&quot;11埼玉県&quot;, &quot;12千葉県&quot;,&quot;13東京都&quot;,&quot;14神奈川県&quot;, &quot;15新潟県&quot;,&quot;16富山県&quot;,&quot;17石川県&quot;,&quot;18福井県&quot;, &quot;19山梨県&quot;,&quot;20長野県&quot;,&quot;21岐阜県&quot;,&quot;22静岡県&quot;, &quot;23愛知県&quot;, &quot;24三重県&quot;,&quot;25滋賀県&quot;,&quot;26京都府&quot;,&quot;27大阪府&quot;, &quot;28兵庫県&quot;,&quot;29奈良県&quot;,&quot;30和歌山県&quot;, &quot;31鳥取県&quot;,&quot;32島根県&quot;,&quot;33岡山県&quot;,&quot;34広島県&quot;, &quot;35山口県&quot;, &quot;36徳島県&quot;,&quot;37香川県&quot;,&quot;38愛媛県&quot;,&quot;39高知県&quot;, &quot;40福岡県&quot;,&quot;41佐賀県&quot;,&quot;42長崎県&quot;,&quot;43熊本県&quot;, &quot;44大分県&quot;,&quot;45宮崎県&quot;,&quot;46鹿児島県&quot;, &quot;47沖縄県&quot;) print(prefnameJ) ## [1] &quot;01北海道&quot; &quot;02青森県&quot; &quot;03岩手県&quot; &quot;04宮城県&quot; &quot;05秋田県&quot; &quot;06山形県&quot; &quot;07福島県&quot; &quot;08茨城県&quot; ## [9] &quot;09栃木県&quot; &quot;10群馬県&quot; &quot;11埼玉県&quot; &quot;12千葉県&quot; &quot;13東京都&quot; &quot;14神奈川県&quot; &quot;15新潟県&quot; &quot;16富山県&quot; ## [17] &quot;17石川県&quot; &quot;18福井県&quot; &quot;19山梨県&quot; &quot;20長野県&quot; &quot;21岐阜県&quot; &quot;22静岡県&quot; &quot;23愛知県&quot; &quot;24三重県&quot; ## [25] &quot;25滋賀県&quot; &quot;26京都府&quot; &quot;27大阪府&quot; &quot;28兵庫県&quot; &quot;29奈良県&quot; &quot;30和歌山県&quot; &quot;31鳥取県&quot; &quot;32島根県&quot; ## [33] &quot;33岡山県&quot; &quot;34広島県&quot; &quot;35山口県&quot; &quot;36徳島県&quot; &quot;37香川県&quot; &quot;38愛媛県&quot; &quot;39高知県&quot; &quot;40福岡県&quot; ## [41] &quot;41佐賀県&quot; &quot;42長崎県&quot; &quot;43熊本県&quot; &quot;44大分県&quot; &quot;45宮崎県&quot; &quot;46鹿児島県&quot; &quot;47沖縄県&quot; print(prefnameJ)で都道府県名を出力しています。ここで[1]はprefnameJというベクトルの中の第１要素を意味しています。出力が長い場合、改行されるごとに先頭の要素番号が出力されます。 # 以下のデータは # 総務省「統計でみる都道府県のすがた2020」 # より抜粋している。 # 変数の対応関係 # A1101_総人口【人】 # B1101_総面積（北方地域及び竹島を除く）【ｈａ】 # D110101_市町村数【‐】 A1101&lt;-c(5286000, #北海道 1263000,1241000,2316000,981000,1090000,1864000, #東北 2877000,1946000,1952000,7330000,6255000,13822000,9177000, #関東 2246000,1050000,1143000,774000, #新潟＋北陸 817000,2063000,1997000,3659000,7537000, #中部 1791000,1412000,2591000,8813000,5484000,1339000,935000, #近畿 560000,680000,1898000,2817000,1370000, #中国 736000,962000,1352000,706000, #四国 5107000,819000,1341000,1757000,1144000,1081000,1614000, #九州 1448000) #沖縄 B1101&lt;-c(7842077, 964565,1527501,728223,1163752,932315,1378390, 609733,640809,636228,379775,515761,219396,241616, 1258423,424761,418605,419052, 446527,1356156,1062129,777735,517296, 577442,401738,461220,190529,840095,369094,472465, 350714,670807,711433,847961,611253, 414675,187678,567624,710363, 498651,244070,413090,740950,634073,773532,918702, 228105) D110101&lt;-c(179, 40,33,35,25,35,59, 44,25,35,63,54,62,33, 30,15,19,17, 27,77,42,35,54, 29,19,26,43,41,39,30, 19,19,27,23,19, 24,17,20,34, 60,20,21,45,18,26,43, 41) testDB&lt;-data.frame(cbind(prefcode,prefnameJ,A1101,B1101,D110101)) head(testDB) ## prefcode prefnameJ A1101 B1101 D110101 ## 1 1 01北海道 5286000 7842077 179 ## 2 2 02青森県 1263000 964565 40 ## 3 3 03岩手県 1241000 1527501 33 ## 4 4 04宮城県 2316000 728223 35 ## 5 5 05秋田県 981000 1163752 25 ## 6 6 06山形県 1090000 932315 35 3.4 データの型 コンピュータが保存しているデータには、型があります。言語によっては事前にどの型で読み込むかを宣言する必要がありますが、Rは自動で判断します。 型 解説 数値型 整数だけでなく小数点を含む数も対象。一般の四則演算と同様にカッコ内は先に計算される。 文字列型 文字、特殊文字、数字を組み合わせた変数で、文字列型は四則演算は適用できない。文字列型であることを指定するためには、\"(ダブルクオーテーション)で囲む。 論理型 TRUE (真)とFALSE (偽)という２つの値をとる。ブーリアン型と呼ばれることもある。TRUEとFALSEは、TやFと省略の可能。 因子型 女性を0、男性を1とするなど、順序のない(=factor型)カテゴリカルデータを扱う場合に使用。 整数型 値を整数として扱うための型で、入力時に値の後ろにLをつける。 複素型 入力した値を複素数として扱うための型で、入力時に値の後ろにiをつける。 データを整理している途中で自分では意図せずともデータの型が変わってしまう場合があります。そのような場合はデータの型を変換する必要があります。 例えば、上の例で、A1101というベクトルは、数値型として読み込まれています。そのため、平均を計算することができます。 is.numeric(A1101) ## [1] TRUE mean(A1101) ## [1] 2690277 ところが、データフレームとしてベクトルをまとめるステップで文字列データに変換されています。そのため、データフレームの中にあるA1101の平均が計算できません。 is.numeric(testDB$A1101) ## [1] FALSE str(testDB$A1101) ## chr [1:47] &quot;5286000&quot; &quot;1263000&quot; &quot;1241000&quot; &quot;2316000&quot; &quot;981000&quot; &quot;1090000&quot; &quot;1864000&quot; &quot;2877000&quot; &quot;1946000&quot; &quot;1952000&quot; ... mean(testDB$A1101) ## Warning in mean.default(testDB$A1101): argument is not numeric or logical: returning NA ## [1] NA chrという記号が文字列型であることを示しています。そのため、データの型を文字列型から数値型に変換する必要があります。 testDB$A1101&lt;-as.numeric(testDB$A1101) mean(testDB$A1101) ## [1] 2690277 また、データの尺度にもいくつか種類があります。以下の表はこちらから引用しています (p114)。 尺度 例 適用可能な演算 名義尺度 果物、りんご、バナナ、オレンジなど ==, != 順序尺度 ホテルのレーティング、５つ星、４つ星など ==, != 比率尺度 長さ、１インチ、1.5インチ、2インチなど ==, !=, &lt;,&gt;,+,-,*,/ 間隔尺度 日付、2012/05/15, 2015/04/17など ==, !=, &lt;,&gt;,+,- 3.5 パッケージの考え方 Rにはpackageという概念があります。プログラミング言語は様々な用途が想定されています。学術研究に限っても、経済学で使用する内容と工学系あるいは医学系で利用する内容は大きく異なります。これらの用途全てに対応するようにR本体を備えてしまうとリソースの無駄が生じます。そのため、Rでは、R本体の機能を最小限に制限し、自身の目的に合わせて必要な道具を付け足していく方式をとっています。その付け足す道具をpackageと呼んでいます。 packageは一回だけインストールする必要があります。インストールはインターネットを使用しておこないますので、インターネットに接続していることが必要です。そして、インストール済みのpackageでも使用する際は毎回呼び出す必要があります。この呼び出しは自身の端末の中にあるものを呼び出すので、インターネット接続は不要です。 文房具に例えると、水彩画を描くために絵の具が必要なので、絵の具を文具店に買いにいくことがインストールです。いざ、今から絵の具を使って絵を描くぞ、というタイミングで絵の具をパレットの上に広げることが「呼び出し」です。 3.6 外部ファイルの読み込み では実際にpackageを使って、外部ファイルを読み込んでみましょう。 デフォルトのRではエクセルファイルをそのまま読むことはできません。ここではエクセルファイルの読み込みに、readxlというpackageを使用します。 # 一度だけインストールが必要 #install.packages(&quot;readxl&quot;) # ライブラリコマンドでの読み込みは毎回必要 library(readxl) # 変数の対応関係 # A1101_総人口【人】 # A1301_15歳未満人口【人】 # A1303_65歳以上人口【人】 # B1101_ 総面積（北方地域及び竹島を除く）【ｈａ】 # B1103_ 可住地面積【ｈａ】 # B4107_ 雪日数（年間）【日】 # B4108_ 日照時間（年間）【時間】 # D110101_市町村数【‐】 # E6102_大学数【校】 # E6302_大学学生数【人】 # F610201_超過実労働時間数（男）【時間】 # F610202_超過実労働時間数（女）【時間】 # H110202_空き家数【戸】 #自分のパソコンに保存してあるエクセルファイルを読み込む場合は、 #以下でディレクトリを変更して実行 #getwd() # 現在の作業ディレクトリを確認 #setwd(&quot;/users/yamamoto/R/ForTeaching&quot;) # 作業ディレクトリの変更 #ウェブサイトから直接ダウンロードする場合 url1&lt;-&quot;https://yamamoto-masashi.github.io/DSlec/20201028sample.xls&quot; download.file(url1,destfile=&quot;20201028sample.xls&quot;) # エクセルファイルの読み込み # ヘッダ部分を読み飛ばしている # sheet=1を変更することで別のシートも読める sampleDB&lt;-readxl::read_excel(&quot;20201028sample.xls&quot;,skip=5,sheet=1) ## New names: ## • `` -&gt; `...1` ## • `` -&gt; `...2` # 列１と列２の名前を変更している。 names(sampleDB)[1:2]&lt;-c(&quot;prefcode&quot;,&quot;prefnameJ&quot;) head(sampleDB) ## # A tibble: 6 × 16 ## prefcode prefn…¹ A1101 A1301 A1303 B1101 B1103 B4107 B4108 D110101 E6102 E6302 F610201 F610202 H110202 Kanto ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 01北海… 5.29e6 577000 1.66e6 7.84e6 2.24e6 131 1742. 179 38 78122 15 8 379800 0 ## 2 2 02青森… 1.26e6 137000 4.12e5 9.65e5 3.23e5 117 1642 40 10 15196 14 7 88700 0 ## 3 3 03岩手… 1.24e6 140000 4.03e5 1.53e6 3.71e5 106 1778. 33 6 11373 15 7 93500 0 ## 4 4 04宮城… 2.32e6 276000 6.43e5 7.28e5 3.15e5 63 1998. 35 14 48623 17 8 130500 0 ## 5 5 05秋田… 9.81e5 98000 3.57e5 1.16e6 3.20e5 101 1526. 25 7 8947 13 7 60800 0 ## 6 6 06山形… 1.09e6 127000 3.58e5 9.32e5 2.88e5 89 1765 35 6 11609 16 7 54200 0 ## # … with abbreviated variable name ¹​prefnameJ 表の変数名の下の&lt;dbl&gt;は変数が数値型であることを示しています。 # read_excel()関数で読み込んだ場合は、文字列になっていないので、平均が計算可能。 mean(sampleDB$A1101) ## [1] 2690277 3.7 描画系のpackageの例 以下では、例として、こちらから各種スポーツのフィールドやコートを描くpackageをインストールして、実際に描画するデモを示したいと思います。 注意：このpackageはグラフ作成の有名packageであるggplot2に依存しているので、以下のコマンドの実行には、ggplot2のインストールも必要です。 # packageのインストールコマンド # 以下でsportyRというpackageをインストールしている #install.packages(&#39;sportyR&#39;) # 以下のコマンドでsportRを呼び出す library(sportyR) library(sportyR) # Create a 100m by 75m FIFA pitch geom_soccer( &quot;fifa&quot;, pitch_updates = list( pitch_length = 100, pitch_width = 75 ) ) #NBAのコート geom_basketball(&quot;nba&quot;, display_range = &quot;offense&quot;, rotation = 270) #カーリングのコート geom_curling(&quot;wcf&quot;, display_range = &quot;house&quot;) 3.7.1 packageの応用例: 野球 packageは複雑な作業を関数化してくれているとも言え、便利なものである。さらに複数のpackageを同時に利用することでさらに便利になる場合も多い。以下ではSportyRで描写したスタジアムにMLBのデータを操作できるbaseballrというpackageを使って打球の情報を追加してみる。 MLBの公式と思われるBaseball Savantでは、StatCastと呼ばれる高性能カメラなどを駆使して記録された試合中の一球ごとのボールの動きがプレイヤーや結果の情報と一緒に公開されている。 以下は2021年と2022年(ただし9月15日まで)の大谷翔平選手のバッテイング記録をプロットしたものである。 # インストールしていない場合、以下も実行 #install.packages(&quot;baseballr&quot;) #install.packages(&quot;dplyr&quot;) #install.packages(&quot;ggplot2&quot;) library(baseballr) library(dplyr) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union library(ggplot2) #最初に調べたいプレイヤーのIDを探す PID&lt;-playerid_lookup(&quot;Ohtani&quot;) #これをみると大谷翔平のIDは660271であることがわかる。 Ohtani2021 &lt;- scrape_statcast_savant_batter(&quot;2021-04-01&quot;, &quot;2021-09-30&quot;, batterid = 660271) #みやすくするためにエラーなどを削除 events2&lt;- c(&quot;single&quot;,&quot;double&quot;,&quot;triple&quot;,&quot;home_run&quot;,&quot;field_out&quot;) # hc_xから125.42を、また、hc_yを198.27から引いているのは打球データの原点をSportyRのホームベースに合わせるためのおまじないで、以下のサイトを参考にして作成した。 #https://baseballwithr.wordpress.com/2021/04/26/spray-charts-using-the-sportyr-package/ # また同じサイトを参考にして、単位をfeetに合わせるために2.5をかけている Ohtani2021 |&gt; filter(hc_x&gt;0 | hc_y&gt;0)|&gt; #見逃したボールを排除するため filter(events %in% events2)|&gt; mutate(location_x = hc_x - 125.42, location_y = 198.27 - hc_y) |&gt; mutate(location_x = 2.5 * (hc_x - 125.42), location_y = 2.5 * (198.27 - hc_y))-&gt;OhtaniBatDB2021 geom_baseball(league = &quot;MLB&quot;) + geom_point(data=OhtaniBatDB2021,aes(location_x, location_y, color = events)) + # scale_colour_manual(values = # c(&quot;orange&quot;,&quot;white&quot;, &quot;red&quot;,&quot;blue&quot;,&quot;pink&quot;)) + ggtitle(&quot;Shohei Ohtani Batting - 2021&quot;) # # 2022年 # Ohtani2022 &lt;- scrape_statcast_savant_batter(&quot;2022-04-01&quot;, &quot;2022-09-15&quot;, batterid = 660271) Ohtani2022 |&gt; filter(hc_x&gt;0 | hc_y&gt;0)|&gt; #見逃したボールを排除するため filter(events %in% events2)|&gt; mutate(location_x = hc_x - 125.42, location_y = 198.27 - hc_y) |&gt; mutate(location_x = 2.5 * (hc_x - 125.42), location_y = 2.5 * (198.27 - hc_y))-&gt;OhtaniBatDB2022 geom_baseball(league = &quot;MLB&quot;) + geom_point(data=OhtaniBatDB2022,aes(location_x, location_y, color = events)) + # scale_colour_manual(values = # c(&quot;orange&quot;,&quot;white&quot;, &quot;red&quot;,&quot;blue&quot;,&quot;pink&quot;)) + ggtitle(&quot;Shohei Ohtani Batting - 2022&quot;) 次に大谷選手の投球をみてみよう。 #カラーパレットの追加 #install.packages(&quot;viridis&quot;) library(viridis) ## Loading required package: viridisLite library(RColorBrewer) OhtaniP2021&lt;-scrape_statcast_savant_pitcher(&quot;2021-04-01&quot;, &quot;2021-09-30&quot;, pitcherid = 660271) #以下のコードはこのサイトから #https://throughthefencebaseball.com/data-analytics-creating-a-pitching-spray-chart-with-rstudio/ ##Drawing The Strike Zone x &lt;- c(-.95,.95,.95,-.95,-.95) z &lt;- c(1.6,1.6,3.5,3.5,1.6) #store in dataframe sz &lt;- data.frame(x,z) ##Changing Pitch Names pitch_desc &lt;- OhtaniP2021$pitch_type ##Changing Pitch Names pitch_desc[which(pitch_desc==&#39;CH&#39;)] &lt;- &quot;Changeup&quot; pitch_desc[which(pitch_desc==&#39;CU&#39;)] &lt;- &quot;Curveball&quot; pitch_desc[which(pitch_desc==&#39;FC&#39;)] &lt;- &quot;Cutter&quot; pitch_desc[which(pitch_desc==&#39;FF&#39;)] &lt;- &quot;Four seam&quot; pitch_desc[which(pitch_desc==&#39;FS&#39;)] &lt;- &quot;Split Flinger&quot; pitch_desc[which(pitch_desc==&#39;FT&#39;)] &lt;- &quot;Two-Seam&quot; pitch_desc[which(pitch_desc==&#39;KC&#39;)] &lt;- &quot;Kuckle-Curve&quot; pitch_desc[which(pitch_desc==&#39;SI&#39;)] &lt;- &quot;Sinker&quot; pitch_desc[which(pitch_desc==&#39;SL&#39;)] &lt;- &quot;Slider&quot; #イニング別 ggplot() + ##First plotting the strike zone that we created geom_path(data = sz, aes(x=x, y=z)) + coord_equal() + ##Now plotting the actual pitches geom_point(data = OhtaniP2021, aes(x = plate_x, y = plate_z, size = release_speed, color = pitch_desc),alpha = 0.5) + scale_size(range = c(-1.0,2.5))+ scale_color_brewer(palette=&quot;Dark2&quot;) + labs(size = &quot;Speed&quot;, color = &quot;Pitch Type&quot;, title = &quot; Shohei Ohtani: Pitch Chart (2021, inning)&quot;) + ylab(&quot;Feet Above Homeplate&quot;) + xlab(&quot;Feet From Homeplate&quot;) + theme(plot.title=element_text(face=&quot;bold&quot;,hjust=-.015,vjust=0, colour=&quot;#3C3C3C&quot;,size=20), plot.subtitle=element_text(face=&quot;plain&quot;, hjust= -.015, vjust= .09, colour=&quot;#3C3C3C&quot;, size = 12)) + theme(axis.text.x=element_text(vjust = .5,size=11, colour=&quot;#535353&quot;,face=&quot;bold&quot;)) + theme(axis.text.y=element_text(size=11,colour=&quot;#535353&quot;,face=&quot;bold&quot;)) + theme(axis.title.y=element_text(size=11,colour=&quot;#535353&quot;,face=&quot;bold&quot;, vjust=1.5)) + theme(axis.title.x=element_text(size=11,colour=&quot;#535353&quot;,face=&quot;bold&quot;, vjust=0)) + theme(panel.grid.major.y = element_line(color = &quot;#bad2d4&quot;, size = .5)) + theme(panel.grid.major.x = element_line(color = &quot;#bdd2d4&quot;, size = .5)) + theme(panel.background = element_rect(fill = &quot;white&quot;)) + facet_wrap(~ inning) #カウント別 ggplot() + ##First plotting the strike zone that we created geom_path(data = sz, aes(x=x, y=z)) + coord_equal() + ##Now plotting the actual pitches geom_point(data = OhtaniP2021, aes(x = plate_x, y = plate_z, size = release_speed, color = pitch_desc),alpha = 0.5) + scale_size(range = c(-1.0,2.5))+ scale_color_brewer(palette=&quot;Dark2&quot;) + labs(size = &quot;Speed&quot;, color = &quot;Pitch Type&quot;, title = &quot; Shohei Ohtani: Pitch Chart (2021, count)&quot;) + ylab(&quot;Feet Above Homeplate&quot;) + xlab(&quot;Feet From Homeplate&quot;) + theme(plot.title=element_text(face=&quot;bold&quot;,hjust=-.015,vjust=0, colour=&quot;#3C3C3C&quot;,size=20), plot.subtitle=element_text(face=&quot;plain&quot;, hjust= -.015, vjust= .09, colour=&quot;#3C3C3C&quot;, size = 12)) + theme(axis.text.x=element_text(vjust = .5,size=11, colour=&quot;#535353&quot;,face=&quot;bold&quot;)) + theme(axis.text.y=element_text(size=11,colour=&quot;#535353&quot;,face=&quot;bold&quot;)) + theme(axis.title.y=element_text(size=11,colour=&quot;#535353&quot;,face=&quot;bold&quot;, vjust=1.5)) + theme(axis.title.x=element_text(size=11,colour=&quot;#535353&quot;,face=&quot;bold&quot;, vjust=0)) + theme(panel.grid.major.y = element_line(color = &quot;#bad2d4&quot;, size = .5)) + theme(panel.grid.major.x = element_line(color = &quot;#bdd2d4&quot;, size = .5)) + theme(panel.background = element_rect(fill = &quot;white&quot;)) + facet_wrap(~ balls+strikes) 同様に2022年(9月15日まで)の投球もプロットしてみる。 OhtaniP2022&lt;-scrape_statcast_savant_pitcher(&quot;2022-04-01&quot;, &quot;2022-09-15&quot;, pitcherid = 660271) ##Changing Pitch Names pitch_desc &lt;- OhtaniP2022$pitch_type ##Changing Pitch Names pitch_desc[which(pitch_desc==&#39;CH&#39;)] &lt;- &quot;Changeup&quot; pitch_desc[which(pitch_desc==&#39;CU&#39;)] &lt;- &quot;Curveball&quot; pitch_desc[which(pitch_desc==&#39;FC&#39;)] &lt;- &quot;Cutter&quot; pitch_desc[which(pitch_desc==&#39;FF&#39;)] &lt;- &quot;Four seam&quot; pitch_desc[which(pitch_desc==&#39;FS&#39;)] &lt;- &quot;Split Flinger&quot; pitch_desc[which(pitch_desc==&#39;FT&#39;)] &lt;- &quot;Two-Seam&quot; pitch_desc[which(pitch_desc==&#39;KC&#39;)] &lt;- &quot;Kuckle-Curve&quot; pitch_desc[which(pitch_desc==&#39;SI&#39;)] &lt;- &quot;Sinker&quot; pitch_desc[which(pitch_desc==&#39;SL&#39;)] &lt;- &quot;Slider&quot; #イニング別 ggplot() + ##First plotting the strike zone that we created geom_path(data = sz, aes(x=x, y=z)) + coord_equal() + ##Now plotting the actual pitches geom_point(data = OhtaniP2022, aes(x = plate_x, y = plate_z, size = release_speed, color = pitch_desc),alpha = 0.5) + scale_size(range = c(-1.0,2.5))+ scale_color_brewer(palette=&quot;Dark2&quot;) + labs(size = &quot;Speed&quot;, color = &quot;Pitch Type&quot;, title = &quot; Shohei Ohtani: Pitch Chart (2022, inning)&quot;) + ylab(&quot;Feet Above Homeplate&quot;) + xlab(&quot;Feet From Homeplate&quot;) + theme(plot.title=element_text(face=&quot;bold&quot;,hjust=-.015,vjust=0, colour=&quot;#3C3C3C&quot;,size=20), plot.subtitle=element_text(face=&quot;plain&quot;, hjust= -.015, vjust= .09, colour=&quot;#3C3C3C&quot;, size = 12)) + theme(axis.text.x=element_text(vjust = .5,size=11, colour=&quot;#535353&quot;,face=&quot;bold&quot;)) + theme(axis.text.y=element_text(size=11,colour=&quot;#535353&quot;,face=&quot;bold&quot;)) + theme(axis.title.y=element_text(size=11,colour=&quot;#535353&quot;,face=&quot;bold&quot;, vjust=1.5)) + theme(axis.title.x=element_text(size=11,colour=&quot;#535353&quot;,face=&quot;bold&quot;, vjust=0)) + theme(panel.grid.major.y = element_line(color = &quot;#bad2d4&quot;, size = .5)) + theme(panel.grid.major.x = element_line(color = &quot;#bdd2d4&quot;, size = .5)) + theme(panel.background = element_rect(fill = &quot;white&quot;)) + facet_wrap(~ inning) #カウント別 ggplot() + ##First plotting the strike zone that we created geom_path(data = sz, aes(x=x, y=z)) + coord_equal() + ##Now plotting the actual pitches geom_point(data = OhtaniP2022, aes(x = plate_x, y = plate_z, size = release_speed, color = pitch_desc),alpha = 0.5) + scale_size(range = c(-1.0,2.5))+ scale_color_brewer(palette=&quot;Dark2&quot;) + labs(size = &quot;Speed&quot;, color = &quot;Pitch Type&quot;, title = &quot; Shohei Ohtani: Pitch Chart (2022, count)&quot;) + ylab(&quot;Feet Above Homeplate&quot;) + xlab(&quot;Feet From Homeplate&quot;) + theme(plot.title=element_text(face=&quot;bold&quot;,hjust=-.015,vjust=0, colour=&quot;#3C3C3C&quot;,size=20), plot.subtitle=element_text(face=&quot;plain&quot;, hjust= -.015, vjust= .09, colour=&quot;#3C3C3C&quot;, size = 12)) + theme(axis.text.x=element_text(vjust = .5,size=11, colour=&quot;#535353&quot;,face=&quot;bold&quot;)) + theme(axis.text.y=element_text(size=11,colour=&quot;#535353&quot;,face=&quot;bold&quot;)) + theme(axis.title.y=element_text(size=11,colour=&quot;#535353&quot;,face=&quot;bold&quot;, vjust=1.5)) + theme(axis.title.x=element_text(size=11,colour=&quot;#535353&quot;,face=&quot;bold&quot;, vjust=0)) + theme(panel.grid.major.y = element_line(color = &quot;#bad2d4&quot;, size = .5)) + theme(panel.grid.major.x = element_line(color = &quot;#bdd2d4&quot;, size = .5)) + theme(panel.background = element_rect(fill = &quot;white&quot;)) + facet_wrap(~ balls+strikes) 3.7.2 packageの応用例：バスケ 2021-2022シーズンのNBAトロントラプターズのshort chartを作ってみよう。NBAはAPIでデータを公開しているようで、nbastatRというパッケージでダウンロードできる。nbastatRの詳細はここで確認できる(英語)。 Sys.setenv(&quot;VROOM_CONNECTION_SIZE&quot; = 131072 * 2) # install.packages(&quot;devtools&quot;) library(devtools) # devtools::install_github(&quot;abresler/nbastatR&quot;) library(nbastatR) # devtools::install_github(&quot;lbenz730/ncaahoopR&quot;) library(ncaahoopR) TOR &lt;- teams_shots(teams = &quot;Toronto Raptors&quot;,seasons = 2022) ## Toronto Raptors 2021-22 shot data # 以下のYouTubeより # https://www.youtube.com/watch?v=ZQ8fqSnvWcc TOR$locationX&lt;-TOR$locationX/10 TOR$locationY&lt;-TOR$locationY/10-41.75 # NBAのコート geom_basketball(league = &quot;nba&quot;, display_range = &quot;offense&quot;, x_trans = 0, y_trans=0, rotation = 270) + geom_point(data=TOR,aes(locationX, locationY, color = isShotMade)) + # scale_colour_manual(values = # c(&quot;orange&quot;,&quot;white&quot;, &quot;red&quot;,&quot;blue&quot;,&quot;pink&quot;)) + ggtitle(&quot;Shot Chart - Toronto Raptors (2021-2022)&quot;) 次にこのシーズンにトロントラプターズでプレイした渡邊雄太選手のshot chartを作ってみよう。 TOR |&gt; filter(namePlayer==&quot;Yuta Watanabe&quot;)-&gt;TOR_YW geom_basketball(league = &quot;nba&quot;, display_range = &quot;offense&quot;, x_trans = 0, y_trans=0, rotation = 270) + geom_point(data=TOR_YW,aes(locationX, locationY, color = isShotMade)) + ggtitle(&quot;Shot Chart - Toronto Raptors (Yuta Watanabe, 2021-2022)&quot;) "],["chapter04.html", "chapter: 4 可視化(1)：ggplot2によるグラフ作成 4.1 可視化の重要性 4.2 Rによる可視化のデモ 4.3 ggplot2の考え方 4.4 ggplot2の事例", " chapter: 4 可視化(1)：ggplot2によるグラフ作成 Rを使用することの大きなメリットの一つが多彩なグラフィック機能です。グラフなどを用いて、データを可視化することで自分の分析対象をより深く理解できるようになります。 4.1 可視化の重要性 はじめにサンプルデータを用いて、可視化の持つ意味について考えます。 # install.packages(&quot;datasets&quot;) library(datasets) print(anscombe) ## x1 x2 x3 x4 y1 y2 y3 y4 ## 1 10 10 10 8 8.04 9.14 7.46 6.58 ## 2 8 8 8 8 6.95 8.14 6.77 5.76 ## 3 13 13 13 8 7.58 8.74 12.74 7.71 ## 4 9 9 9 8 8.81 8.77 7.11 8.84 ## 5 11 11 11 8 8.33 9.26 7.81 8.47 ## 6 14 14 14 8 9.96 8.10 8.84 7.04 ## 7 6 6 6 8 7.24 6.13 6.08 5.25 ## 8 4 4 4 19 4.26 3.10 5.39 12.50 ## 9 12 12 12 8 10.84 9.13 8.15 5.56 ## 10 7 7 7 8 4.82 7.26 6.42 7.91 ## 11 5 5 5 8 5.68 4.74 5.73 6.89 このデータ例は、統計学者のフランク・アンスコムが1973年に紹介した例です。この例では、\\(x\\) の平均(=mean)は\\(9\\)、\\(x\\) の標準偏差(=sd)は\\(3.32\\)、\\(y\\)の平均が\\(7.50\\) (小数第2位まで一致)、\\(y\\)の標準偏差が \\(2.03\\) (小数第3位まで一致)、と等しくなっています。 # 記述統計を出力するためのpackage # include.packages(&quot;psych) library(psych) descriptive_statistics&lt;-describe(anscombe,skew = FALSE, ranges = FALSE) print(descriptive_statistics) ## vars n mean sd se ## x1 1 11 9.0 3.32 1.00 ## x2 2 11 9.0 3.32 1.00 ## x3 3 11 9.0 3.32 1.00 ## x4 4 11 9.0 3.32 1.00 ## y1 5 11 7.5 2.03 0.61 ## y2 6 11 7.5 2.03 0.61 ## y3 7 11 7.5 2.03 0.61 ## y4 8 11 7.5 2.03 0.61 また、\\(x_i\\)と\\(y_i\\)の間の相関係数も少数第３位で四捨五入して\\(0.82\\)と一致しています。 \\[ r = \\frac{\\frac{1}{n}\\sum_{i=1}^{n}(x_{i}-\\overline{x})(y_{i}-\\overline{y})}{\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(x_{i}-\\overline{x})^{2}}\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(y_{i}-\\overline{y})^{2}}} = \\frac{s_{xy}}{s_{x}s_{y}} \\] #x1とy1の相関係数 x1y1&lt;-cor(anscombe$x1,anscombe$y1) x2y2&lt;-cor(anscombe$x2,anscombe$y2) x3y3&lt;-cor(anscombe$x3,anscombe$y3) x4y4&lt;-cor(anscombe$x4,anscombe$y4) options(digits=2) # 表示桁数を小数点第２位までに変える print(c(x1y1,x2y2,x3y3,x4y4)) ## [1] 0.82 0.82 0.82 0.82 ところが、このデータをプロットしてみると以下のようになります (描画に用いたggplot2の解説はこの後に行います)。 # 4組のグラフを作成する plotx1y1&lt;-ggplot(anscombe)+geom_point(aes(x=x1,y=y1),size=3)+ xlim(2.5,20)+ylim(2.5,12.9)+ggtitle(&quot;Set 1&quot;) plotx2y2&lt;-ggplot(anscombe)+geom_point(aes(x=x2,y=y2),size=3)+ xlim(2.5,20)+ylim(2.5,12.9)+ggtitle(&quot;Set 2&quot;) plotx3y3&lt;-ggplot(anscombe)+geom_point(aes(x=x3,y=y3),size=3)+ xlim(2.5,20)+ylim(2.5,12.9)+ggtitle(&quot;Set 3&quot;) plotx4y4&lt;-ggplot(anscombe)+geom_point(aes(x=x4,y=y4),size=3)+ xlim(2.5,20)+ylim(2.5,12.9)+ggtitle(&quot;Set 4&quot;) # このpackageでグラフを組み合わせる #install.packages(&quot;patchwork&quot;) library(patchwork) plotx1y1 + plotx2y2 +plotx3y3+plotx4y4+ plot_layout(ncol = 2, heights = c(5, 4)) このように全く異なるデータの分布をしていることがわかります。要約統計量だけをみて判断せずに常にグラフにデータをプロットしてみることが重要です。 4.2 Rによる可視化のデモ コマンドラインで図を作成することははじめは面倒に思うかもしれません。しかし、どのようなグラフを作成するかを一つ一つ命令に書きますので、一度作成してしまえばコピーペーストで簡単に複製することができます。ところがクリックベースでグラフを作成した場合、完成したグラフをコピーしたとしても必ずしも元のグラフと同じにはなりません。ズレた場合にも目測で直す必要があります。 Rによる可視化の例を公式デモにて確認します。 demo(graphics) ## ## ## demo(graphics) ## ---- ~~~~~~~~ ## ## &gt; # Copyright (C) 1997-2009 The R Core Team ## &gt; ## &gt; require(datasets) ## ## &gt; require(grDevices); require(graphics) ## ## &gt; ## Here is some code which illustrates some of the differences between ## &gt; ## R and S graphics capabilities. Note that colors are generally specified ## &gt; ## by a character string name (taken from the X11 rgb.txt file) and that line ## &gt; ## textures are given similarly. The parameter &quot;bg&quot; sets the background ## &gt; ## parameter for the plot and there is also an &quot;fg&quot; parameter which sets ## &gt; ## the foreground color. ## &gt; ## &gt; ## &gt; x &lt;- stats::rnorm(50) ## ## &gt; opar &lt;- par(bg = &quot;white&quot;) ## ## &gt; plot(x, ann = FALSE, type = &quot;n&quot;) ## ## &gt; abline(h = 0, col = gray(.90)) ## ## &gt; lines(x, col = &quot;green4&quot;, lty = &quot;dotted&quot;) ## ## &gt; points(x, bg = &quot;limegreen&quot;, pch = 21) ## ## &gt; title(main = &quot;Simple Use of Color In a Plot&quot;, ## + xlab = &quot;Just a Whisper of a Label&quot;, ## + col.main = &quot;blue&quot;, col.lab = gray(.8), ## + cex.main = 1.2, cex.lab = 1.0, font.main = 4, font.lab = 3) ## ## &gt; ## A little color wheel. This code just plots equally spaced hues in ## &gt; ## a pie chart. If you have a cheap SVGA monitor (like me) you will ## &gt; ## probably find that numerically equispaced does not mean visually ## &gt; ## equispaced. On my display at home, these colors tend to cluster at ## &gt; ## the RGB primaries. On the other hand on the SGI Indy at work the ## &gt; ## effect is near perfect. ## &gt; ## &gt; par(bg = &quot;gray&quot;) ## ## &gt; pie(rep(1,24), col = rainbow(24), radius = 0.9) ## ## &gt; title(main = &quot;A Sample Color Wheel&quot;, cex.main = 1.4, font.main = 3) ## ## &gt; title(xlab = &quot;(Use this as a test of monitor linearity)&quot;, ## + cex.lab = 0.8, font.lab = 3) ## ## &gt; ## We have already confessed to having these. This is just showing off X11 ## &gt; ## color names (and the example (from the postscript manual) is pretty &quot;cute&quot;. ## &gt; ## &gt; pie.sales &lt;- c(0.12, 0.3, 0.26, 0.16, 0.04, 0.12) ## ## &gt; names(pie.sales) &lt;- c(&quot;Blueberry&quot;, &quot;Cherry&quot;, ## + &quot;Apple&quot;, &quot;Boston Cream&quot;, &quot;Other&quot;, &quot;Vanilla Cream&quot;) ## ## &gt; pie(pie.sales, ## + col = c(&quot;purple&quot;,&quot;violetred1&quot;,&quot;green3&quot;,&quot;cornsilk&quot;,&quot;cyan&quot;,&quot;white&quot;)) ## ## &gt; title(main = &quot;January Pie Sales&quot;, cex.main = 1.8, font.main = 1) ## ## &gt; title(xlab = &quot;(Don&#39;t try this at home kids)&quot;, cex.lab = 0.8, font.lab = 3) ## ## &gt; ## Boxplots: I couldn&#39;t resist the capability for filling the &quot;box&quot;. ## &gt; ## The use of color seems like a useful addition, it focuses attention ## &gt; ## on the central bulk of the data. ## &gt; ## &gt; par(bg=&quot;cornsilk&quot;) ## ## &gt; n &lt;- 10 ## ## &gt; g &lt;- gl(n, 100, n*100) ## ## &gt; x &lt;- rnorm(n*100) + sqrt(as.numeric(g)) ## ## &gt; boxplot(split(x,g), col=&quot;lavender&quot;, notch=TRUE) ## ## &gt; title(main=&quot;Notched Boxplots&quot;, xlab=&quot;Group&quot;, font.main=4, font.lab=1) ## ## &gt; ## An example showing how to fill between curves. ## &gt; ## &gt; par(bg=&quot;white&quot;) ## ## &gt; n &lt;- 100 ## ## &gt; x &lt;- c(0,cumsum(rnorm(n))) ## ## &gt; y &lt;- c(0,cumsum(rnorm(n))) ## ## &gt; xx &lt;- c(0:n, n:0) ## ## &gt; yy &lt;- c(x, rev(y)) ## ## &gt; plot(xx, yy, type=&quot;n&quot;, xlab=&quot;Time&quot;, ylab=&quot;Distance&quot;) ## ## &gt; polygon(xx, yy, col=&quot;gray&quot;) ## ## &gt; title(&quot;Distance Between Brownian Motions&quot;) ## ## &gt; ## Colored plot margins, axis labels and titles. You do need to be ## &gt; ## careful with these kinds of effects. It&#39;s easy to go completely ## &gt; ## over the top and you can end up with your lunch all over the keyboard. ## &gt; ## On the other hand, my market research clients love it. ## &gt; ## &gt; x &lt;- c(0.00, 0.40, 0.86, 0.85, 0.69, 0.48, 0.54, 1.09, 1.11, 1.73, 2.05, 2.02) ## ## &gt; par(bg=&quot;lightgray&quot;) ## ## &gt; plot(x, type=&quot;n&quot;, axes=FALSE, ann=FALSE) ## ## &gt; usr &lt;- par(&quot;usr&quot;) ## ## &gt; rect(usr[1], usr[3], usr[2], usr[4], col=&quot;cornsilk&quot;, border=&quot;black&quot;) ## ## &gt; lines(x, col=&quot;blue&quot;) ## ## &gt; points(x, pch=21, bg=&quot;lightcyan&quot;, cex=1.25) ## ## &gt; axis(2, col.axis=&quot;blue&quot;, las=1) ## ## &gt; axis(1, at=1:12, lab=month.abb, col.axis=&quot;blue&quot;) ## ## &gt; box() ## ## &gt; title(main= &quot;The Level of Interest in R&quot;, font.main=4, col.main=&quot;red&quot;) ## ## &gt; title(xlab= &quot;1996&quot;, col.lab=&quot;red&quot;) ## ## &gt; ## A filled histogram, showing how to change the font used for the ## &gt; ## main title without changing the other annotation. ## &gt; ## &gt; par(bg=&quot;cornsilk&quot;) ## ## &gt; x &lt;- rnorm(1000) ## ## &gt; hist(x, xlim=range(-4, 4, x), col=&quot;lavender&quot;, main=&quot;&quot;) ## ## &gt; title(main=&quot;1000 Normal Random Variates&quot;, font.main=3) ## ## &gt; ## A scatterplot matrix ## &gt; ## The good old Iris data (yet again) ## &gt; ## &gt; pairs(iris[1:4], main=&quot;Edgar Anderson&#39;s Iris Data&quot;, font.main=4, pch=19) ## ## &gt; pairs(iris[1:4], main=&quot;Edgar Anderson&#39;s Iris Data&quot;, pch=21, ## + bg = c(&quot;red&quot;, &quot;green3&quot;, &quot;blue&quot;)[unclass(iris$Species)]) ## ## &gt; ## Contour plotting ## &gt; ## This produces a topographic map of one of Auckland&#39;s many volcanic &quot;peaks&quot;. ## &gt; ## &gt; x &lt;- 10*1:nrow(volcano) ## ## &gt; y &lt;- 10*1:ncol(volcano) ## ## &gt; lev &lt;- pretty(range(volcano), 10) ## ## &gt; par(bg = &quot;lightcyan&quot;) ## ## &gt; pin &lt;- par(&quot;pin&quot;) ## ## &gt; xdelta &lt;- diff(range(x)) ## ## &gt; ydelta &lt;- diff(range(y)) ## ## &gt; xscale &lt;- pin[1]/xdelta ## ## &gt; yscale &lt;- pin[2]/ydelta ## ## &gt; scale &lt;- min(xscale, yscale) ## ## &gt; xadd &lt;- 0.5*(pin[1]/scale - xdelta) ## ## &gt; yadd &lt;- 0.5*(pin[2]/scale - ydelta) ## ## &gt; plot(numeric(0), numeric(0), ## + xlim = range(x)+c(-1,1)*xadd, ylim = range(y)+c(-1,1)*yadd, ## + type = &quot;n&quot;, ann = FALSE) ## ## &gt; usr &lt;- par(&quot;usr&quot;) ## ## &gt; rect(usr[1], usr[3], usr[2], usr[4], col=&quot;green3&quot;) ## ## &gt; contour(x, y, volcano, levels = lev, col=&quot;yellow&quot;, lty=&quot;solid&quot;, add=TRUE) ## ## &gt; box() ## ## &gt; title(&quot;A Topographic Map of Maunga Whau&quot;, font= 4) ## ## &gt; title(xlab = &quot;Meters North&quot;, ylab = &quot;Meters West&quot;, font= 3) ## ## &gt; mtext(&quot;10 Meter Contour Spacing&quot;, side=3, line=0.35, outer=FALSE, ## + at = mean(par(&quot;usr&quot;)[1:2]), cex=0.7, font=3) ## ## &gt; ## Conditioning plots ## &gt; ## &gt; par(bg=&quot;cornsilk&quot;) ## ## &gt; coplot(lat ~ long | depth, data = quakes, pch = 21, bg = &quot;green3&quot;) ## ## &gt; par(opar) 4.3 ggplot2の考え方 ggplot2は、Rの中で最もポピュラーな描画packageです。最初は戸惑うかもしれませんが、論理でグラフを作る面白さを一緒に体験しましょう。 ggplot2はグラフを特定のパーツに分けてレイヤーとして作成し、それらを重ねて表現していきます。コマンドとしてはそれぞれのレイヤーを「足し算する」形でグラフを完成していきます。 下の例は最初のコマンドで、ggplot(A,aes(x=B,y=C))で、Aというデータセットを使って、x軸にB、y軸にCを使うグラフの基礎となるレイヤーを作ってね、という命令になります。 # install.packages(&quot;ggplot2&quot;) library(ggplot2) # データフレームの表示 head(midwest) ## # A tibble: 6 × 28 ## PID county state area popto…¹ popde…² popwh…³ popbl…⁴ popam…⁵ popas…⁶ popot…⁷ percw…⁸ percb…⁹ perca…˟ perca…˟ ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 561 ADAMS IL 0.052 66090 1271. 63917 1702 98 249 124 96.7 2.58 0.148 0.377 ## 2 562 ALEXAN… IL 0.014 10626 759 7054 3496 19 48 9 66.4 32.9 0.179 0.452 ## 3 563 BOND IL 0.022 14991 681. 14477 429 35 16 34 96.6 2.86 0.233 0.107 ## 4 564 BOONE IL 0.017 30806 1812. 29344 127 46 150 1139 95.3 0.412 0.149 0.487 ## 5 565 BROWN IL 0.018 5836 324. 5264 547 14 5 6 90.2 9.37 0.240 0.0857 ## 6 566 BUREAU IL 0.05 35688 714. 35157 50 65 195 221 98.5 0.140 0.182 0.546 ## # … with 13 more variables: percother &lt;dbl&gt;, popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;, ## # poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;, percchildbelowpovert &lt;dbl&gt;, ## # percadultpoverty &lt;dbl&gt;, percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;, and abbreviated variable ## # names ¹​poptotal, ²​popdensity, ³​popwhite, ⁴​popblack, ⁵​popamerindian, ⁶​popasian, ⁷​popother, ⁸​percwhite, ## # ⁹​percblack, ˟​percamerindan, ˟​percasian midewestはggplot2に付属しているデータベースで、アメリカ中西部の５つの州(IL, IN, MI, OH,WI)のサンプルデータが保存してあります。 ggplot(data=midwest, aes(x=percollege,y=percadultpoverty)) 結果は上記のようになります。この例では、横軸が各カウンティの大卒割合、縦軸が、貧困割合を示しています。 データそのものは、どうやってプロットするか、を命令しないと描かれません。どうやってとは、棒グラフにするのか、折れ線グラフにするのか、円グラフにするのか、といった見た目の問題です。このどうやっての部分は、geom_XXX()という関数群で指定します。例えば、散布図を作成する場合は、geom_point()となります。 ggplot(data=midwest)+ geom_point(aes(x=percollege,y=percadultpoverty)) デフォルトでは、軸の名称に変数の名前が入るので、これをわかりやすい文言に変更してみましょう。また、タイトルも加えてみます。 ggplot(data=midwest)+ geom_point(aes(x=percollege,y=percadultpoverty))+ theme_gray (base_family = &quot;HiraKakuPro-W3&quot;)+ # 日本語表示のために必要 xlab(&quot;各カウンティにおける大卒の割合 (%)&quot;)+ ylab(&quot;貧困の割合 (%)&quot;)+ ggtitle(&quot;アメリカ中西部５州の現状&quot;) geom_point()のaes()でcolor=XXXと設定することでXXX変数を用いて色分けをすることができます。stateという変数で州の名前が格納されているので、この情報を使って州別に色分けしてみましょう。 ggplot(data=midwest)+ geom_point(aes(x=percollege,y=percadultpoverty,color=state))+ theme_gray (base_family = &quot;HiraKakuPro-W3&quot;)+ # 日本語表示のために必要 xlab(&quot;各カウンティにおける大卒の割合 (%)&quot;)+ ylab(&quot;貧困の割合 (%)&quot;)+ ggtitle(&quot;アメリカ中西部５州の現状&quot;) あるいはfacet_grid()関数で州別に分割することも可能です。 # 横方向への分割 ggplot(data=midwest)+ geom_point(aes(x=percollege,y=percadultpoverty))+ facet_grid(. ~ state)+ # stateでグラフを分割 (横方向) theme_gray (base_family = &quot;HiraKakuPro-W3&quot;)+ # 日本語表示のために必要 xlab(&quot;各カウンティにおける大卒の割合 (%)&quot;)+ ylab(&quot;貧困の割合 (%)&quot;)+ ggtitle(&quot;アメリカ中西部５州の現状&quot;) # 縦方向への分割 ggplot(data=midwest)+ geom_point(aes(x=percollege,y=percadultpoverty))+ facet_grid(state ~.)+ # stateでグラフを分割 (縦方向) theme_gray (base_family = &quot;HiraKakuPro-W3&quot;)+ # 日本語表示のために必要 xlab(&quot;各カウンティにおける大卒の割合 (%)&quot;)+ ylab(&quot;貧困の割合 (%)&quot;)+ ggtitle(&quot;アメリカ中西部５州の現状&quot;) 代表的なgeom_XXX関数は以下の通りです。 関数名 内容 geom_point() 散布図のように点を描画 geom_line() 折れ線グラフを描画 geom_smooth() データのトレンド線を描画 geom_col() 棒グラフの描画 geom_polygon() 長方形など任意の形状のオブジェクトの描画 geom_sf() 空間情報を持つオブジェクトの描画 例えば、棒グラフは以下のように描写できる。 ggplot(midwest)+ geom_col(aes(x=state,y=poptotal))+ theme_gray (base_family = &quot;HiraKakuPro-W3&quot;)+ # 日本語表示のために必要 xlab(&quot;州名&quot;)+ylab(&quot;州全体の人口&quot;) データでは、各州のカウンティレベルでの人口が入っているが自動的に合計されていることに注意。 人口の軸表示がe+06などとなっていますが、これは学術的な標記で\\(10^6\\)を意味しています。これをより一般にわかりやすい標記に変更します。 ここでは、scalesというpackageのlabel_number()関数を使って変更していますが、元のデータの単位を変更する(=1,000,000で割るなど)しても同じです。 また、もう一つの機能として軸を入れ替えるcoord_flip()関数も紹介しています。 #install.packages(&quot;scales&quot;) library(scales) ## ## Attaching package: &#39;scales&#39; ## The following objects are masked from &#39;package:psych&#39;: ## ## alpha, rescale ## The following object is masked from &#39;package:purrr&#39;: ## ## discard ## The following object is masked from &#39;package:viridis&#39;: ## ## viridis_pal ggplot(midwest)+ geom_col(aes(x=state,y=poptotal))+ theme_gray (base_family = &quot;HiraKakuPro-W3&quot;)+ # 日本語表示のために必要 scale_y_continuous(labels = label_number(suffix = &quot;&quot;, scale = 1e-6))+ xlab(&quot;州名&quot;)+ylab(&quot;州全体の人口 (単位：百万人)&quot;)+ coord_flip() label_number()関数のsuffixというオプションは添字という意味で上の例では空欄としていますが任意の文字列を入れることも可能です。例えば百万を意味するmillionから頭文字をとって、Mを追記することが可能です。 また、fill=\"XXXでグラフの色を変更しました。aes()の外で設定している点に注意してください。 #install.packages(&quot;scales&quot;) library(scales) ggplot(midwest)+ geom_col(aes(x=state,y=poptotal), fill=&quot;royalblue&quot;)+ theme_gray (base_family = &quot;HiraKakuPro-W3&quot;)+ # 日本語表示のために必要 scale_y_continuous(labels = label_number(suffix = &quot; M&quot;, scale = 1e-6))+ xlab(&quot;州名&quot;)+ylab(&quot;州全体の人口&quot;)+ coord_flip() aes()の中でfill=XXXを実行した場合、XXXの値によって色分けをすることができます。以下の例では、inmetroという変数で色分けをしています。この変数は、あるカウンティがmetro areaに属していれば１、そうでなければ０をとる変数です。このような変数をダミー変数と呼びます。metro areaは日本でいう人口密度が一定以上のエリアのことで、いわゆる都市化されているエリアと考えてもらえれば良いと思います。 ggplot(midwest)+ geom_col(aes(x=state,y=poptotal,fill=factor(inmetro)))+ theme_gray (base_family = &quot;HiraKakuPro-W3&quot;)+ # 日本語表示のために必要 scale_y_continuous(labels = label_number(suffix = &quot;&quot;, scale = 1e-6))+ xlab(&quot;州名&quot;)+ylab(&quot;州全体の人口 (単位：百万人)&quot;)+ labs(fill=&quot;metro areaダミー&quot;) # 凡例のタイトルを変更している ggplot2には数多くの機能があります。そしてこの機能は日々進化しています。もし、グラフをこのように変更したい、というアイディアが何かあったらまずはgoogle検索してみてください。最初は適切な検索ワードが見つけられずに苦労するかもしれませんが、慣れてくるとかなりの確率で答えが見つかると思います。場合によっては、自分がイメージしていた可視化よりも優れたアイディアに出会えることもあると思います。 最終的なアウトプットの完成度を高めることが最初の目標ですが、その後はその過程の効率化にも目を向けてみてください。自分のスタイルを確立することができたら、それに至る時間を短縮するための様々な方法がggplot2あるいはRには用意されています。 4.4 ggplot2の事例 以下は、このサイトから引用した例です。講義では触れませんが、使いたいものがあれば是非試してみてください。 4.4.1 バブルチャート #Source:http://r-statistics.co/Top50-Ggplot2-Visualizations-MasterList-R-Code.html data(mpg, package=&quot;ggplot2&quot;) # mpg &lt;- read.csv(&quot;http://goo.gl/uEeRGu&quot;) mpg_select &lt;- mpg[mpg$manufacturer %in% c(&quot;audi&quot;, &quot;ford&quot;, &quot;honda&quot;, &quot;hyundai&quot;), ] # Scatterplot theme_set(theme_bw()) # pre-set the bw theme. g &lt;- ggplot(mpg_select, aes(displ, cty)) + labs(subtitle=&quot;mpg: Displacement vs City Mileage&quot;, title=&quot;Bubble chart&quot;) g + geom_jitter(aes(col=manufacturer, size=hwy)) + geom_smooth(aes(col=manufacturer), method=&quot;lm&quot;, se=F) ## `geom_smooth()` using formula &#39;y ~ x&#39; 4.4.2 ロリポップチャート #Source:http://r-statistics.co/Top50-Ggplot2-Visualizations-MasterList-R-Code.html theme_set(theme_bw()) # Prepare data: group mean city mileage by manufacturer. cty_mpg &lt;- aggregate(mpg$cty, by=list(mpg$manufacturer), FUN=mean) # aggregate colnames(cty_mpg) &lt;- c(&quot;make&quot;, &quot;mileage&quot;) # change column names cty_mpg &lt;- cty_mpg[order(cty_mpg$mileage), ] # sort cty_mpg$make &lt;- factor(cty_mpg$make, levels = cty_mpg$make) # to retain the order in plot. head(cty_mpg, 4) ## make mileage ## 9 lincoln 11 ## 8 land rover 12 ## 3 dodge 13 ## 10 mercury 13 # Plot ggplot(cty_mpg, aes(x=make, y=mileage)) + geom_point(size=3) + geom_segment(aes(x=make, xend=make, y=0, yend=mileage)) + labs(title=&quot;Lollipop Chart&quot;, subtitle=&quot;Make Vs Avg. Mileage&quot;, caption=&quot;source: mpg&quot;) + theme(axis.text.x = element_text(angle=65, vjust=0.6)) 4.4.3 ヒストグラム #Source:http://r-statistics.co/Top50-Ggplot2-Visualizations-MasterList-R-Code.html theme_set(theme_classic()) # Histogram on a Continuous (Numeric) Variable g &lt;- ggplot(mpg, aes(displ)) + scale_fill_brewer(palette = &quot;Spectral&quot;) g + geom_histogram(aes(fill=class), binwidth = .1, col=&quot;black&quot;, size=.1) + # change binwidth labs(title=&quot;Histogram with Auto Binning&quot;, subtitle=&quot;Engine Displacement across Vehicle Classes&quot;) g + geom_histogram(aes(fill=class), bins=5, col=&quot;black&quot;, size=.1) + # change number of bins labs(title=&quot;Histogram with Fixed Bins&quot;, subtitle=&quot;Engine Displacement across Vehicle Classes&quot;) 4.4.4 ボックスプロット #Source:http://r-statistics.co/Top50-Ggplot2-Visualizations-MasterList-R-Code.html theme_set(theme_bw()) # plot g &lt;- ggplot(mpg, aes(manufacturer, cty)) g + geom_boxplot() + geom_dotplot(binaxis=&#39;y&#39;, stackdir=&#39;center&#39;, dotsize = .5, fill=&quot;red&quot;) + theme(axis.text.x = element_text(angle=65, vjust=0.6)) + labs(title=&quot;Box plot + Dot plot&quot;, subtitle=&quot;City Mileage vs Class: Each dot represents 1 row in source data&quot;, caption=&quot;Source: mpg&quot;, x=&quot;Class of Vehicle&quot;, y=&quot;City Mileage&quot;) ## Bin width defaults to 1/30 of the range of the data. Pick better value with `binwidth`. 4.4.5 時系列データ #Source:http://r-statistics.co/Top50-Ggplot2-Visualizations-MasterList-R-Code.html #install.packages(&quot;forecast&quot;) library(forecast) ## Registered S3 method overwritten by &#39;quantmod&#39;: ## method from ## as.zoo.data.frame zoo theme_set(theme_classic()) # Subset data nottem_small &lt;- window(nottem, start=c(1920, 1), end=c(1925, 12)) # subset a smaller timewindow # Plot ggseasonplot(AirPassengers) + labs(title=&quot;Seasonal plot: International Airline Passengers&quot;) ggseasonplot(nottem_small) + labs(title=&quot;Seasonal plot: Air temperatures at Nottingham Castle&quot;) インターネットで検索すると、ggplot2の使い方はたくさん出てきます。以下にまとまって学習できるサイトの例をリンクしておきます。個々の問題もほとんどネットで解決できます。検索のコツをつかむまでが大変ですが、エラーメッセージをコピペして検索することから始めると良いと思います。 "],["chapter05.html", "chapter: 5 可視化(2)：ggplot2による地図作成 5.1 パレットの追加 5.2 塗り分け地図の作成 5.3 よりGISライクな地図の作成 5.4 世界地図の活用 5.5 さらに学びたい人へ", " chapter: 5 可視化(2)：ggplot2による地図作成 空間的な広がりのあるデータを扱う際には、地図による可視化がデータの特徴を理解する上で大きな助けになります。グラフ描画に用いたggplot2を拡張することで様々な地図データを描画できることはRの魅力の一つです。 地図を使った描画には、位置情報の正確さをそれほど必要としない場合と地理的情報の精度が極めて情報な場合の２通りが考えられます。前者は、コロプレス図と呼ばれるいわゆる「白地図の塗り分け」のようなものが相当します。後者は、GISと呼ばれる地理情報科学の分野に近いケースで、「迷惑施設が県境付近に立地しやすい」という仮説を検証するなど、正確な地理情報が前提となる場合です。 5.1 パレットの追加 Rの中で簡単に追加できる色の組み合わせを提供しているpackageにRColorBrewerがあります。慣れてきたらこのカラーパレットを参考にして色を変えてみても良いでしょう。 # install.packages(&quot;RColorBrewer&quot;) library(RColorBrewer) display.brewer.all() 5.2 塗り分け地図の作成 はじめに日本の塗り分け地図をなるべく簡単に作成する方法を学びます。NipponMapというpackageでは見やすさを重視して、海岸線など一部を単純化しています。都道府県別の塗り分けなどは地理情報の精度よりも見やすさを優先すべきです。 なお、left_join関数は、left_join(A,B, by=\"C\")であるとき、Cという列をキーにして、AにBの情報を追加する関数です。 #一回だけ以下のインストールが必要 #install.packages(c(&quot;NipponMap&quot;, &quot;tidyverse&quot;)) # ライブラリコマンドでの読み込みは毎回必要 library(readxl) library(NipponMap) library(sf) ## Linking to GEOS 3.10.2, GDAL 3.4.2, PROJ 8.2.1; sf_use_s2() is TRUE library(tidyverse) ## ── Attaching packages ## ────────────────────────────────────────────────────────────────────────── ## tidyverse 1.3.2 ── ## ✔ tibble 3.1.8 ✔ stringr 1.4.1 ## ✔ tidyr 1.2.0 ✔ forcats 0.5.2 ## ✔ readr 2.1.2 ## ── Conflicts ───────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ psych::%+%() masks ggplot2::%+%() ## ✖ scales::alpha() masks psych::alpha(), ggplot2::alpha() ## ✖ readr::col_factor() masks scales::col_factor() ## ✖ scales::discard() masks purrr::discard() ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() #ウェブサイトから直接ダウンロードする場合 url1&lt;-&quot;https://yamamoto-masashi.github.io/DSlec/20201028sample.xls&quot; download.file(url1,destfile=&quot;20201028sample.xls&quot;) # エクセルファイルの読み込み # ヘッダ部分を読み飛ばしている # sheet=1を変更することで別のシートも読める sampleDB&lt;-readxl::read_excel(&quot;20201028sample.xls&quot;,skip=5,sheet=1) ## New names: ## • `` -&gt; `...1` ## • `` -&gt; `...2` # 変数の対応関係 # A1101_総人口【人】 # A1301_15歳未満人口【人】 # A1303_65歳以上人口【人】 # B1101_ 総面積（北方地域及び竹島を除く）【ｈａ】 # B1103_ 可住地面積【ｈａ】 # B4107_ 雪日数（年間）【日】 # B4108_ 日照時間（年間）【時間】 # D110101_市町村数【‐】 # E6102_大学数【校】 # E6302_大学学生数【人】 # F610201_超過実労働時間数（男）【時間】 # F610202_超過実労働時間数（女）【時間】 # H110202_空き家数【戸】 # 列１と列２の名前を変更している。 names(sampleDB)[1:2]&lt;-c(&quot;prefcode&quot;,&quot;prefnameJ&quot;) # データと地図を結合する際にキーの型が同じ必要があるので # 数値型を文字型に変更している。 sampleDB$prefcode&lt;-as.character(sampleDB$prefcode) # 地図の情報はNipponMapから取り出しています。 # この方法は以下で教えていただきました。 # https://ill-identified.hatenablog.com/entry/2020/12/07/134705 Nippon_map &lt;- read_sf(system.file(&quot;shapes/jpn.shp&quot;, package = &quot;NipponMap&quot;)[1], crs = &quot;+proj=longlat +datum=WGS84&quot;) # 地図情報に総務省のデータベースを接続 mapDB&lt;-left_join(Nippon_map,sampleDB, by=c(&quot;SP_ID&quot;=&quot;prefcode&quot;)) # 地図にプロット ggplot(mapDB, aes(fill = B4107)) + geom_sf() + scale_fill_gradientn(colors=brewer.pal(9,&quot;GnBu&quot;))+ theme_gray (base_family = &quot;HiraKakuPro-W3&quot;)+ labs(fill = &quot;年間雪日数(日)&quot;)+ ggtitle(&quot;都道府県別の雪日数 (2018年)&quot;) スペースの都合や見やすさという点で北海道と沖縄県を移動する場合があります。そのような地図もRで作成することができます。なお、この作図は「ジオメトリの移動による日本地図の可視化」を参考にして作成しました。 annotate()関数を使って、始点と終点を与えることで線を引くことができるので、その機能を使って、北海道と沖縄県を区別する線を加えます。 #ジオメトリの直接変更 #北海道の都道府県番号は１、沖縄県は47。 Nippon_map$geometry[1]=Nippon_map$geometry[1]+c(-11, -4) Nippon_map$geometry[47]=Nippon_map$geometry[47]+c(12, 5) #日本地図の描写 ggplot()+ geom_sf(data=Nippon_map, aes(fill=population/10000))+ scale_fill_gradientn(colors=brewer.pal(9,&quot;GnBu&quot;))+ annotate(&quot;segment&quot;, x=129, xend=134.2, y=37, yend=37, color=&quot;gray&quot;, size=1)+ annotate(&quot;segment&quot;, x=134.2, xend=138.5, y=37, yend=41, color=&quot;gray&quot;, size=1)+ annotate(&quot;segment&quot;, x=139.8, xend=141, y=32.2, yend=32.2, color=&quot;gray&quot;, size=1)+ annotate(&quot;segment&quot;, x=138.5, xend=139.8, y=31, yend=32.2, color=&quot;gray&quot;, size=1)+ labs(fill=&quot;万人&quot;, x=&quot;&quot;, y=&quot;&quot;, caption=&quot;Nippomap&quot;)+ ggtitle(&quot;都道府県別人口&quot;)+ theme_bw(base_family = &quot;HiraKakuPro-W3&quot;) 5.3 よりGISライクな地図の作成 以下では地理情報をできるだけ正確に扱った地図の描画について解説します。例として用いるデータは、2020年国勢調査の平塚市（小地域）です。このファイルは、 総務省統計局 &gt;&gt; 小地域 &gt;&gt; 国勢調査 &gt;&gt; 2020年 小地域 &gt;&gt; 世界測地系緯度経度・Shapefile &gt;&gt; 神奈川県 &gt;&gt; 平塚市 でダウンロードできます。 地図情報のうち、ベクターデータは、シェープファイルという形式で利用することがデフォルトになっています。シェープファイルとは、Esri社が開発したGIS用のデータフォーマットで、ポイントデータ(1組以上の緯度、経度情報)、ラインデータ(2組のポイントデータを結んだものの集まり)、ポリゴンデータ(ラインデータを結んだもの)を格納できます。 シェープファイルの拡張子は、.shpですが、シェープファイルはこのファイル単独では動作しません。データをダウンロードするときはついてくる複数のファイル（最低でも３つはある）を全て同じフォルダに保存するようにしてください。 library(sf) map &lt;- read_sf(&quot;Hiratsuka/r2ka14203.shp&quot;, crs = &quot;+proj=longlat +datum=WGS84&quot;) # 平塚市のシェープファイル ggplot(map) + geom_sf() 各町丁・字等別の人口で塗り分けをしてみましょう。 ggplot(map) + geom_sf(aes(fill=JINKO))+ scale_fill_gradientn(colors=brewer.pal(9,&quot;GnBu&quot;))+ theme_gray (base_family = &quot;HiraKakuPro-W3&quot;)+ labs(fill = &quot;単位：人&quot;)+ ggtitle(&quot;国勢調査(2020年)における平塚市の人口 (町丁・字等別)&quot;) さらに鉄道路線、大学の立地などを重ねてみましょう。 以下の例では、鉄道のデータを国土数値情報という国土交通省が運営しているウェブサイトからダウンロードして使っています。このサイトの「4.交通」の中にある「鉄道(ライン）」というデータを使用しています。なお年ごとに路線が変化しているため、国勢調査に合わせて2020年のデータを使用しています。 この鉄道データは全国のJR及び私鉄を全て含むので、このままプロットすると全国の全ての鉄道路線が表示されます。そのため平塚市の路線に限定する必要があります。 そこで使用しているが、st_intersectionという関数です。この関数を使うと二つの地理データに共通の部分だけを残すことができます。鉄道(ライン)データは駅の情報も含むため、駅も赤色で表示しています。 最後に東海大学の位置をannotate関数を使って東海大学の場所を、geom_text関数を使って、東海大学の名称を表示しました。これらの関数は緯度、経度を使って表示することができます。 trainline &lt;- read_sf(&quot;Train/N02-20_RailroadSection.shp&quot;, crs = &quot;+proj=longlat +datum=WGS84&quot;) # 鉄道線路網のシェープファイル trainstation &lt;- read_sf(&quot;Train/N02-20_Station.shp&quot;, crs = &quot;+proj=longlat +datum=WGS84&quot;) # 鉄道駅のシェープファイル # ポリゴンの頂点が重複していると新しいsfではエラーが出るので、 # s2をFALSEにしている # https://stackoverflow.com/questions/68808238/how-to-fix-spherical-geometry-errors-caused-by-conversion-from-geos-to-s2 sf_use_s2(FALSE) ggplot(map)+ geom_sf(aes(fill=JINKO))+ geom_sf(data=st_sf(geometry=st_intersection(st_union(map),st_union(trainline))), color=&quot;black&quot;,size=1)+ geom_sf(data=st_sf(geometry=st_intersection(st_union(map),st_union(trainstation))), color=&quot;red&quot;,size=1)+ annotate(&quot;point&quot;, x = 139.274823, y = 35.365831, colour = &quot;blue&quot;, size=2)+ geom_text(aes(x = 139.266823, y = 35.362831), label = &quot;東海大学&quot;, family = &quot;HiraKakuProN-W3&quot;)+ scale_fill_gradientn(colors=brewer.pal(9,&quot;GnBu&quot;))+ theme_gray (base_family = &quot;HiraKakuPro-W3&quot;)+ labs(fill = &quot;単位：人&quot;)+ xlab(&quot;経度&quot;)+ylab(&quot;緯度&quot;)+ ggtitle(&quot;国勢調査(2020年)における平塚市の人口 (町丁・字等別)&quot;) 何か足りません。そうです。小田急線が描かれていないのです。その理由は、小田急線が平塚市内を通っていないためです。そこで鉄道ラインデータの切り出しの際にのみ、隣の秦野市のデータを加えて、小田急線を表示したいと思います。 HadMap &lt;- read_sf(&quot;Hadano/r2ka14211.shp&quot;, crs = &quot;+proj=longlat +datum=WGS84&quot;) # 秦野市のシェープファイル ggplot()+ geom_sf(data=map,aes(fill=JINKO))+ geom_sf(data=st_sf(geometry=st_intersection(st_union(map),st_union(trainline))), color=&quot;black&quot;,size=1)+ geom_sf(data=st_sf(geometry=st_intersection(st_union(map),st_union(trainstation))), color=&quot;red&quot;,size=1)+ geom_sf(data=st_sf(geometry=st_intersection(st_union(HadMap),st_union(trainline))), color=&quot;black&quot;,size=1)+ geom_sf(data=st_sf(geometry=st_intersection(st_union(HadMap),st_union(trainstation))), color=&quot;red&quot;,size=1)+ annotate(&quot;point&quot;, x = 139.274823, y = 35.365831, colour = &quot;blue&quot;, size=2)+ geom_text(aes(x = 139.266823, y = 35.362831), label = &quot;東海大学&quot;, family = &quot;HiraKakuProN-W3&quot;)+ geom_text(aes(x = 139.28, y = 35.388), label = &quot;小田急線&quot;, family = &quot;HiraKakuProN-W3&quot;)+ geom_text(aes(x = 139.283, y = 35.328), label = &quot;新幹線&quot;, family = &quot;HiraKakuProN-W3&quot;)+ geom_text(aes(x = 139.375, y = 35.327), label = &quot;東海道線&quot;, family = &quot;HiraKakuProN-W3&quot;)+ scale_fill_gradientn(colors=brewer.pal(9,&quot;GnBu&quot;))+ theme_gray (base_family = &quot;HiraKakuPro-W3&quot;)+ labs(fill = &quot;単位：人&quot;)+ xlab(&quot;経度&quot;)+ylab(&quot;緯度&quot;)+ xlim(139.23,139.38)+ ggtitle(&quot;国勢調査(2020年)における平塚市の人口 (町丁・字等別)&quot;) 続いて、地価公示のデータをプロットしてみよう。地価公示の詳細はこちらをご覧ください。 地価公示とは、地価公示法に基づいて、国土交通省土地鑑定委員会が、適正な地価の 形成に寄与するために、毎年1月1日時点における標準地の正常な価格を3月に公示 (約26,000地点で実施）するもので、社会・経済活動についての制度インフラとなって います。 主な役割 1.一般の土地の取引に対して指標を与えること 2.不動産鑑定の規準となること 3.公共事業用地の取得価格算定の規準となること 4.土地の相続評価および固定資産税評価についての基準となること 5.国土利用計画法による土地の価格審査の規準となること 等 位置情報のついた地価公示のデータは 国土数値情報 &gt;&gt; 1. 国土 &gt;&gt; 地価公示 (ポイント) &gt;&gt; 神奈川県 &gt;&gt; 令和4年 にアクセスすると入手できる。 以下では、地価の動向をみるために、より大きなスケールで可視化を行いたいので、ベースマップを平塚市から神奈川県に変更する。 #地価公示 KanagawaPrice&lt;-read_sf(&quot;KanagawaLandPrice/L01-22_14.shp&quot;) #地価を整数型に KanagawaPrice$price&lt;-as.integer(KanagawaPrice$L01_006) # 用途が住宅のもののみに KanagawaPrice %&gt;% filter(L01_027==&quot;住宅&quot;) -&gt; KanagawaPriceHome #神奈川県の行政界 KanaSHP&lt;-read_sf(&quot;KanagawaBorder/N03-22_14_220101.shp&quot;, crs = &quot;+proj=longlat +datum=WGS84&quot;) # 神奈川県のシェープファイル ggplot() + geom_sf(data=KanaSHP,fill=&quot;white&quot;)+ geom_sf(data=st_sf(geometry=st_intersection(st_union(KanaSHP),st_union(trainline))), color=&quot;black&quot;,size=0.5)+ geom_sf(data=st_sf(geometry=st_intersection(st_union(KanaSHP),st_union(trainstation))), color=&quot;red&quot;,size=0.5)+ geom_sf(data=KanagawaPriceHome,aes(color = price/1000),size=0.2)+ scale_color_gradientn(colors=brewer.pal(9,&quot;YlOrRd&quot;))+ theme_bw(base_family = &quot;HiraKakuPro-W3&quot;)+ labs(color = &quot;単位：千円/m^2&quot;)+ ggtitle(&quot;神奈川県の地価公示(令和4年)&quot;) これをさらにヒートマップの形で表してみよう。 #install.packages(&quot;akima&quot;) library(akima) # sf objectから緯度経度を取り出す KanaCoords&lt;-st_coordinates(KanagawaPrice$geometry) # XおよびYとして緯度経度を追加する（もっと美しいやり方あると思いますが） KanaPrice&lt;-cbind(KanagawaPrice,KanaCoords) # ポイントデータを補間する interpdf &lt;-interp2xyz(interp(x=KanaPrice$X, y=KanaPrice$Y, z=KanaPrice$price/1000, duplicate=&quot;mean&quot;), data.frame=TRUE) interpdf %&gt;% filter(!is.na(z)) %&gt;% tbl_df() %&gt;% ggplot() + geom_sf(data=KanaSHP)+ geom_contour(aes(x = x, y = y, z = z),color = &quot;white&quot;, alpha = 1) + geom_tile(aes(x = x, y = y, z = z, fill = z,alpha=0.5)) + scale_fill_distiller(palette=&quot;Spectral&quot;, na.value=&quot;white&quot;) + theme_gray(base_family = &quot;HiraKakuPro-W3&quot;)+ labs(fill=&quot;単位：千円/m^2&quot;)+ guides(alpha=FALSE)+xlab(&quot;&quot;)+ylab(&quot;&quot;)+ ggtitle(&quot;神奈川県の地価公示(令和3年)&quot;)-&gt;p print(p) 次に二つの地図を１枚の図としてプロットしてみよう。 使用するデータは一般廃棄物処理の施設立地のデータで以下でダウンロードできる。 国土数値情報 &gt;&gt; 3. 地域 &gt;&gt; 廃棄物処理施設 (ポイント) &gt;&gt; 神奈川県(平成24年) はじめにそれぞれの地図を作成する。 library(cowplot) setwd(&quot;~/R/bookdown/datalecture2022/&quot;) # 産業廃棄物のデータの読み込み KanaIndWaste&lt;-read_sf(&quot;KanagawaWaste/P15-12_14_GML/P15-12_14_IndustrialWasteDisposalFacilities.shp&quot;, options = c(&quot;encoding=CP932&quot;), crs=&quot;WGS84&quot;) # 一般廃棄物のデータの読み込み KanaMswWaste&lt;-read_sf(&quot;KanagawaWaste/P15-12_14_GML/P15-12_14_GeneralWasteDisposalFacilities.shp&quot;, options = c(&quot;encoding=CP932&quot;), crs=&quot;WGS84&quot;) # 神奈川県のポリゴン KanaMap&lt;-read_sf(&quot;KanagawaBorder/N03-22_14_220101.shp&quot;, options = c(&quot;encoding=CP932&quot;), crs=&quot;WGS84&quot;) #湘南地域の選択 KanaMap |&gt; filter(N03_004 %in% c(&quot;平塚市&quot;,&quot;秦野市&quot;,&quot;伊勢原市&quot;,&quot;大磯町&quot;, &quot;二宮町&quot;,&quot;寒川町&quot;,&quot;藤沢市&quot;,&quot;茅ヶ崎市&quot;))-&gt; ShonanMap #湘南地域の地図をShaMapと命名 ShoMap&lt;- geom_sf(data=ShonanMap, size=0.8) #湘南地域の可視化 ggplot()+ geom_sf(data=KanaMap, size=0.1)+ShoMap+ theme(axis.ticks = element_blank(), axis.text.x = element_blank(), axis.text.y = element_blank())-&gt;ggm1 ggm1 #湘南地域の一般廃棄物処理施設の取り出し # 秦野と伊勢原は２市で一部事務組合を組織して、共同で整備している。 KanaMswWaste %&gt;% filter(P15_002 %in% c(&quot;平塚市&quot;,&quot;秦野市伊勢原市環境衛生組合&quot;,&quot;大磯町&quot;, &quot;二宮町&quot;,&quot;寒川町&quot;,&quot;藤沢市&quot;,&quot;茅ヶ崎市&quot;)) -&gt; ShonanMswMap #平塚市の一般廃棄物施設の地図をHiratsukaMswMapと命名 ShoMswMap&lt;- geom_sf(data=ShonanMswMap, size=3) #施設の可視化 ggplot()+ ShoMap+ ShoMswMap+ theme_gray (base_family = &quot;HiraKakuPro-W3&quot;)+ annotate(&quot;point&quot;, x = 139.274823, y = 35.365831, colour = &quot;white&quot;, size=5)+ geom_text(aes(x = 139.266823, y = 35.362831), label = &quot;東海大学&quot;, color=&quot;blue&quot;, family = &quot;HiraKakuProN-W3&quot;)+ ggtitle(&quot;湘南地域の一般廃棄物処理施設&quot;)-&gt;ggm2 ggm2 最後に2つの地図を合わせる。 # Combining both maps gg_inset_map1 = ggdraw() + draw_plot(ggm2) + draw_plot(ggm1, x = 0.10, y = 0.17, width = 0.25, height = 0.25)+ theme_gray (base_family = &quot;HiraKakuPro-W3&quot;) gg_inset_map1 この地図をみると廃棄物処理施設は、藤沢市の一部を除けば市町村境界に近い場所に立地しているようにもみえる。皆さんはどう思うだろうか？ 5.4 世界地図の活用 Natural Earthというサイトに世界の地図データが無料でダウンロード可能である。以下では、rnaturalearthというpackageを使って、世界地図を描写する方法を紹介する。 library(sf) library(tidyverse) #install.packages(&quot;rnaturalearth&quot;) #install.packages(&quot;rnaturalearthdata&quot;) library(rnaturalearth) #Natural Earth World_map&lt;- ne_countries(scale=&quot;medium&quot;, returnclass=&quot;sf&quot;) ggplot()+ geom_sf(data=World_map) #最初の6行 World_map %&gt;% head() ## Simple feature collection with 6 features and 63 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: -70 ymin: -18 xmax: 75 ymax: 60 ## CRS: +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0 ## scalerank featurecla labelrank sovereignt sov_a3 adm0_dif level type admin adm0_a3 ## 0 3 Admin-0 country 5 Netherlands NL1 1 2 Country Aruba ABW ## 1 1 Admin-0 country 3 Afghanistan AFG 0 2 Sovereign country Afghanistan AFG ## 2 1 Admin-0 country 3 Angola AGO 0 2 Sovereign country Angola AGO ## 3 1 Admin-0 country 6 United Kingdom GB1 1 2 Dependency Anguilla AIA ## 4 1 Admin-0 country 6 Albania ALB 0 2 Sovereign country Albania ALB ## 5 3 Admin-0 country 6 Finland FI1 1 2 Country Aland ALD ## geou_dif geounit gu_a3 su_dif subunit su_a3 brk_diff name name_long brk_a3 brk_name ## 0 0 Aruba ABW 0 Aruba ABW 0 Aruba Aruba ABW Aruba ## 1 0 Afghanistan AFG 0 Afghanistan AFG 0 Afghanistan Afghanistan AFG Afghanistan ## 2 0 Angola AGO 0 Angola AGO 0 Angola Angola AGO Angola ## 3 0 Anguilla AIA 0 Anguilla AIA 0 Anguilla Anguilla AIA Anguilla ## 4 0 Albania ALB 0 Albania ALB 0 Albania Albania ALB Albania ## 5 0 Aland ALD 0 Aland ALD 0 Aland Aland Islands ALD Aland ## brk_group abbrev postal formal_en formal_fr note_adm0 note_brk name_sort name_alt mapcolor7 ## 0 &lt;NA&gt; Aruba AW Aruba &lt;NA&gt; Neth. &lt;NA&gt; Aruba &lt;NA&gt; 4 ## 1 &lt;NA&gt; Afg. AF Islamic State of Afghanistan &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; Afghanistan &lt;NA&gt; 5 ## 2 &lt;NA&gt; Ang. AO People&#39;s Republic of Angola &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; Angola &lt;NA&gt; 3 ## 3 &lt;NA&gt; Ang. AI &lt;NA&gt; &lt;NA&gt; U.K. &lt;NA&gt; Anguilla &lt;NA&gt; 6 ## 4 &lt;NA&gt; Alb. AL Republic of Albania &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; Albania &lt;NA&gt; 1 ## 5 &lt;NA&gt; Aland AI Åland Islands &lt;NA&gt; Fin. &lt;NA&gt; Aland &lt;NA&gt; 4 ## mapcolor8 mapcolor9 mapcolor13 pop_est gdp_md_est pop_year lastcensus gdp_year economy ## 0 2 2 9 1.0e+05 2258 NA 2010 NA 6. Developing region ## 1 6 8 7 2.8e+07 22270 NA 1979 NA 7. Least developed region ## 2 2 6 1 1.3e+07 110300 NA 1970 NA 7. Least developed region ## 3 6 6 3 1.4e+04 109 NA NA NA 6. Developing region ## 4 4 1 6 3.6e+06 21810 NA 2001 NA 6. Developing region ## 5 1 4 6 2.7e+04 1563 NA NA NA 2. Developed region: nonG7 ## income_grp wikipedia fips_10 iso_a2 iso_a3 iso_n3 un_a3 wb_a2 wb_a3 woe_id adm0_a3_is adm0_a3_us ## 0 2. High income: nonOECD NA &lt;NA&gt; AW ABW 533 533 AW ABW NA ABW ABW ## 1 5. Low income NA &lt;NA&gt; AF AFG 004 004 AF AFG NA AFG AFG ## 2 3. Upper middle income NA &lt;NA&gt; AO AGO 024 024 AO AGO NA AGO AGO ## 3 3. Upper middle income NA &lt;NA&gt; AI AIA 660 660 &lt;NA&gt; &lt;NA&gt; NA AIA AIA ## 4 4. Lower middle income NA &lt;NA&gt; AL ALB 008 008 AL ALB NA ALB ALB ## 5 1. High income: OECD NA &lt;NA&gt; AX ALA 248 248 &lt;NA&gt; &lt;NA&gt; NA ALA ALD ## adm0_a3_un adm0_a3_wb continent region_un subregion region_wb name_len long_len ## 0 NA NA North America Americas Caribbean Latin America &amp; Caribbean 5 5 ## 1 NA NA Asia Asia Southern Asia South Asia 11 11 ## 2 NA NA Africa Africa Middle Africa Sub-Saharan Africa 6 6 ## 3 NA NA North America Americas Caribbean Latin America &amp; Caribbean 8 8 ## 4 NA NA Europe Europe Southern Europe Europe &amp; Central Asia 7 7 ## 5 NA NA Europe Europe Northern Europe Europe &amp; Central Asia 5 13 ## abbrev_len tiny homepart geometry ## 0 5 4 NA MULTIPOLYGON (((-70 12, -70... ## 1 4 NA 1 MULTIPOLYGON (((75 37, 75 3... ## 2 4 NA 1 MULTIPOLYGON (((14 -5.9, 14... ## 3 4 NA NA MULTIPOLYGON (((-63 18, -63... ## 4 4 NA 1 MULTIPOLYGON (((20 43, 20 4... ## 5 5 5 NA MULTIPOLYGON (((21 60, 21 6... 5.4.1 世界地図を利用した可視化 所得階層別の塗り分け ggplot()+ geom_sf(data=World_map, aes(fill=income_grp), color=&quot;white&quot;, size=0.001)+ labs(fill=&quot;所得グループ&quot;, caption=&quot;出典：Natural Earth&quot;)+ ggtitle(&quot;世界の所得分布&quot;)+ theme_bw(base_family = &quot;HiraKakuPro-W3&quot;)+ theme(legend.position=&quot;bottom&quot;)+ guides(fill=guide_legend(nrow=2)) 世界地図に用いられる投影法の1つであるロビンソン図法（Robinson projection）を用いた可視化。 ggplot()+ geom_sf(data=World_map, aes(fill=income_grp), color=&quot;white&quot;, size=0.001)+ scale_fill_brewer(palette = &quot;PuBu&quot;,direction=-1)+ # direction=-1でパレットが逆順に labs(fill=&quot;所得グループ&quot;, caption=&quot;出典：Natural Earth&quot;)+ ggtitle(&quot;世界の所得分布（ロビンソン図法）&quot;)+ theme_bw(base_family = &quot;HiraKakuPro-W3&quot;)+ coord_sf(crs=st_crs(&quot;ESRI:54030&quot;))+ theme(legend.position=&quot;bottom&quot;)+ guides(fill=guide_legend(nrow=2)) 5.4.2 世界銀行データの可視化 世界銀行の公開データは、World Bank Open Dataというサイトでアクセスできる。このサイトを眺めるだけでも多くの情報を得ることができるので、開発問題に興味がある場合はアクセスしてみよう。このサイトの情報は膨大であるため、WDIというpackageを用いてデータにアクセスするのが効率的である。 なお、自分が探しているindicatorのIDを探す場合は、このサイトを参照のこと。 #install.packages(&quot;WDI&quot;) library(WDI) #使用する指標 CO2percapita&lt;- WDI(indicator=&quot;EN.ATM.CO2E.PC&quot;, extra=TRUE, start=2015, end=2015) #列名の変更 CO2percapita %&gt;% rename(CO2pc=EN.ATM.CO2E.PC) -&gt; CO2percapita #地図データと世界銀行データの結合 CO2pc_map&lt;- left_join(World_map, CO2percapita, by=c(&quot;iso_a3&quot;=&quot;iso3c&quot;)) #南極大陸削除(好み) CO2pc_map %&gt;% filter(iso_a3!=&quot;ATA&quot;) -&gt; CO2pc_map #地図の描写 ggplot()+ geom_sf(data=CO2pc_map, aes(fill=CO2pc), color=&quot;white&quot;, size=0.001)+ scale_fill_gradientn(colors=brewer.pal(5,&quot;PuBu&quot;))+ labs(fill=&quot;トン/人&quot;, caption=&quot;出典：Natural Earth, The World Bank&quot;)+ ggtitle(&quot;一人あたりCO2排出量（2015年）&quot;)+ coord_sf(crs=st_crs(&quot;ESRI:54030&quot;))+ theme_bw(base_family = &quot;HiraKakuPro-W3&quot;)+ theme(legend.position=&quot;bottom&quot;) 5.5 さらに学びたい人へ このチャプターの内容の多くは、Rによる地理空間データの可視化を参照しています。このサイトではこの他にもたくさんの美しい地図の作成方法が解説されていますので、地図を用いた分析を行いたい場合は必ず確認しましょう。 また、ここに特定の市町村を選んで、さらに分析を加えた例を掲載しています。地域の分析に興味のある人は試してみてください。 "],["chapter06.html", "chapter: 6 Rによる統計的仮説検定 6.1 データの読み込み 6.2 平均・分散・標準偏差 6.3 分散・標準偏差が大きいことのイメージ 6.4 データフレームの要約 6.5 相関係数 6.6 仮説検定 6.7 t検定", " chapter: 6 Rによる統計的仮説検定 統計学の講義で学んだ検定をRで実行する方法を学びます。 # ライブラリコマンドでの読み込みは毎回必要 library(readxl) library(ggplot2) library(dplyr) #library(foreign) # Macユーザ向けの日本語フォント theme_set(theme_gray(base_size = 10, base_family = &quot;HiraginoSans-W3&quot;)) #ウィンドウズユーザー向けの日本語フォント #windowsFonts(YuGothic = windowsFont(&quot;Yu Gothic&quot;)) #theme_set(theme_gray(base_size = 10, base_family = &quot;YuGothic&quot;)) 6.1 データの読み込み # 変数の対応関係 # A1101_総人口【人】 # A1301_15歳未満人口【人】 # A1303_65歳以上人口【人】 # B1101_ 総面積（北方地域及び竹島を除く）【ｈａ】 # B1103_ 可住地面積【ｈａ】 # B4107_ 雪日数（年間）【日】 # B4108_ 日照時間（年間）【時間】 # D110101_市町村数【‐】 # E6102_大学数【校】 # E6302_大学学生数【人】 # F610201_超過実労働時間数（男）【時間】 # F610202_超過実労働時間数（女）【時間】 # H110202_空き家数【戸】 #ウェブサイトから直接ダウンロードする場合 url1&lt;-&quot;https://yamamoto-masashi.github.io/DSlec/20201028sample.xls&quot; download.file(url1,destfile=&quot;20201028sample.xls&quot;) # エクセルファイルの読み込み # ヘッダ部分を読み飛ばしている # sheet=1を変更することで別のシートも読める sampleDB&lt;-read_excel(&quot;20201028sample.xls&quot;,skip=5,sheet=1) # 列１と列２の名前を変更している。 names(sampleDB)[1:2]&lt;-c(&quot;prefcode&quot;,&quot;prefnameJ&quot;) 6.2 平均・分散・標準偏差 都道府県別の市町村数を例に基本統計量の計算方法を示す。 #平均 mean(sampleDB$D110101) ## [1] 37 # 合計する sum(sampleDB$D110101) ## [1] 1741 #データの個数を求める length(sampleDB$D110101) ## [1] 47 #中央値を求める median(sampleDB$D110101) ## [1] 33 #最大値を求める max(sampleDB$D110101) ## [1] 179 #最小値を求める min(sampleDB$D110101) ## [1] 15 # 度数分布 table(sampleDB$D110101) ## ## 15 17 18 19 20 21 23 24 25 26 27 29 30 33 34 35 39 40 41 42 43 44 45 54 59 60 62 63 ## 1 2 1 5 2 1 1 1 2 2 2 1 2 2 1 4 1 1 2 1 2 1 1 2 1 1 1 1 ## 77 179 ## 1 1 #ヒストグラムを描く (標準) hist(sampleDB$D110101) #ヒストグラムを描く (ggplot2で) sampleDB %&gt;% ggplot()+ geom_histogram(aes(x=D110101,fill=factor(Kanto)), bins=80,position=&quot;nudge&quot;,alpha=0.7)+ geom_density(aes(x=D110101,y=..count..),fill=&quot;blue&quot;, alpha=0.3) + labs(fill=&quot;Kanto dummy&quot;)+xlab(&quot;Number of municipalities&quot;)+ geom_vline(xintercept = 33) #平方根を求める sqrt(sampleDB$D110101) ## [1] 13.4 6.3 5.7 5.9 5.0 5.9 7.7 6.6 5.0 5.9 7.9 7.3 7.9 5.7 5.5 3.9 4.4 4.1 5.2 8.8 6.5 5.9 ## [23] 7.3 5.4 4.4 5.1 6.6 6.4 6.2 5.5 4.4 4.4 5.2 4.8 4.4 4.9 4.1 4.5 5.8 7.7 4.5 4.6 6.7 4.2 ## [45] 5.1 6.6 6.4 以下の定義は覚えておこう。 母集団 (population)：調査対象となる要素の全体 標本 (sample)：母集団から抽出された個体の集まり 一致性 (consistency)：標本の数が多くなったら、サンプルの推定量が母数に一致すること 不偏性 (unbiasedness)：標本の推定量が母数に等しくなること 標本分散: \\(s_{xx}=\\frac{1}{n}\\sum_{i=1}^{n}(x_i-\\overline{x})^2\\) 不偏分散: \\(\\sigma_xx =\\frac{1}{n-1}\\sum_{i=1}^{n}(x_i-\\overline{x})^2=\\frac{n}{n-1}\\frac{1}{n}\\sum_{i=1}^{n}(x_i-\\overline{x})^2=\\frac{n}{n-1}s_{xx}\\) 推定量としては、不偏分散が望ましい。なお、分散の平方根を標準偏差(standard deviation)と呼ぶ。 #不偏分散を求める var(sampleDB$D110101) ## [1] 659 #標準偏差を求める sd(sampleDB$D110101) ## [1] 26 6.3 分散・標準偏差が大きいことのイメージ # # A大学の共通試験結果 # # １から２５まで１刻みで largeV&lt;-1:25 mean(largeV) ## [1] 13 sd(largeV) ## [1] 7.4 # # B大学の共通試験の結果 # smallV&lt;-c(10,11,12,13,14,15,16, 10,11,12,13,14,15,16, 10,11,12,13,14,15,16, 13,13,13,13) mean(smallV) ## [1] 13 sd(smallV) ## [1] 1.9 curve(dnorm(x,mean=mean(largeV),sd=sd(largeV)),ylim=c(0,0.25),from=1,to=25) curve(dnorm(x,mean=mean(smallV),sd=sd(smallV)),ylim=c(0,0.25),from=1,to=25,add=TRUE) ggplot(data=data.frame(X=c(1,25)), aes(x=X))+ stat_function(fun=dnorm, args=list(mean=mean(largeV), sd=sd(largeV)),color=&quot;red&quot;)+ stat_function(fun=dnorm, args=list(mean=mean(smallV), sd=sd(smallV)),color=&quot;blue&quot;)+ ylab(&quot;density&quot;)+ylim(0.01,0.25) ## Warning: Removed 62 row(s) containing missing values (geom_path). 6.4 データフレームの要約 summary(sampleDB) ## prefcode prefnameJ A1101 A1301 A1303 B1101 ## Min. : 1 Length:47 Min. : 560000 Min. : 71000 Min. : 177000 Min. : 187678 ## 1st Qu.:12 Class :character 1st Qu.: 1085500 1st Qu.: 132000 1st Qu.: 339000 1st Qu.: 416640 ## Median :24 Mode :character Median : 1614000 Median : 216000 Median : 506000 Median : 609733 ## Mean :24 Mean : 2690277 Mean : 328043 Mean : 756915 Mean : 793555 ## 3rd Qu.:36 3rd Qu.: 2704000 3rd Qu.: 326500 3rd Qu.: 783000 3rd Qu.: 808915 ## Max. :47 Max. :13822000 Max. :1550000 Max. :3189000 Max. :7842077 ## B1103 B4107 B4108 D110101 E6102 E6302 F610201 ## Min. : 85553 Min. : 0 Min. :1526 Min. : 15 Min. : 2 Min. : 6710 Min. :11.0 ## 1st Qu.: 131898 1st Qu.: 13 1st Qu.:1898 1st Qu.: 22 1st Qu.: 6 1st Qu.: 11696 1st Qu.:15.0 ## Median : 205919 Median : 20 Median :2120 Median : 33 Median : 9 Median : 18376 Median :16.0 ## Mean : 260924 Mean : 35 Mean :2070 Mean : 37 Mean : 17 Mean : 55312 Mean :15.9 ## 3rd Qu.: 298550 3rd Qu.: 54 3rd Qu.:2238 3rd Qu.: 42 3rd Qu.: 18 3rd Qu.: 43465 3rd Qu.:17.0 ## Max. :2237238 Max. :131 Max. :2391 Max. :179 Max. :138 Max. :669191 Max. :20.0 ## F610202 H110202 Kanto ## Min. : 5.0 Min. : 39900 Min. :0.00 ## 1st Qu.: 7.0 1st Qu.: 82700 1st Qu.:0.00 ## Median : 8.0 Median :126800 Median :0.00 ## Mean : 7.7 Mean :180615 Mean :0.15 ## 3rd Qu.: 9.0 3rd Qu.:197250 3rd Qu.:0.00 ## Max. :10.0 Max. :809900 Max. :1.00 6.5 相関係数 二つの変数の直線的な関係を数値的に表す方法として相関係数 (correlation)がある。 相関係数の定義は以下の通り \\[r_{xy}=\\frac{s_{xy}}{\\sqrt{s_{xx}}\\sqrt{s_{yy}}}\\] ただし、 \\[s_{xy}=\\frac{1}{n}\\sum_{i=1}^{n}\\left(x_i-\\overline{x}\\right)\\left(y_i-\\overline{y}\\right)\\] は共分散である。 # 二つのデータは無相関であるという帰無仮説を検定 # 市町村数と都道府県の総面接 cor.test(sampleDB$D110101,sampleDB$B1101) ## ## Pearson&#39;s product-moment correlation ## ## data: sampleDB$D110101 and sampleDB$B1101 ## t = 10, df = 45, p-value = 6e-13 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.71 0.90 ## sample estimates: ## cor ## 0.83 # 市町村数と都道府県の可住地面接 cor.test(sampleDB$D110101,sampleDB$B1103) ## ## Pearson&#39;s product-moment correlation ## ## data: sampleDB$D110101 and sampleDB$B1103 ## t = 12, df = 45, p-value = 3e-15 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.77 0.93 ## sample estimates: ## cor ## 0.87 # 相関関係の可視化 plot(sampleDB$D110101,sampleDB$B1101) # ggplotによる可視化 sampleDB %&gt;% ggplot()+ geom_point(aes(x=D110101,y=B1101/1000,color=factor(Kanto)))+ xlab(&quot;Number of municipalities&quot;)+ylab(&quot;Total Area (thousand ha)&quot;)+ labs(color=&quot;Kanto Dummy&quot;) # 相関係数を３つ表示 sampleDB %&gt;% select(D110101,B1101,B1103)-&gt;sampleDBsmall library(psych) pairs.panels(sampleDBsmall) 6.6 仮説検定 ミクロ経済学は一定の仮定をもうけることで「必ず○○となる」と言った確定的な結論を提供する。しかし場合によってはその仮定が非現実的であることもある。実証分析は実際のデータに基づいているので、その方が優れているかというと必ずしもそうではない。例えば、教室にいる女性に「一番好きな食べ物は何か？」と聞いて、仮に全員が「焼き芋」と答えたとしても「世界中の女性が最も好きな食べ物は焼き芋である」ということにはならない。 母集団全体からデータを集めることは通常不可能である。そこで、どの程度の確率で自分の仮説が確からしいかを数量的に評価する方法が求められる。これが推測統計学を基礎とした計量経済学の基本的な考え方である。 そのための重要な考え方が、統計的仮説検定と呼ばれるものである。これは自身が主張したい仮説と逆の命題を「帰無仮説」として設定し、この「帰無仮説」がめったに起らないかどうかを確認する。このめったに起らないの「めったに」を有意水準といい、経済学では通常100回やったら5回以下しか起こらないような事象を指す。これを有意水準5%での仮説検定と呼ぶ。もし、有意水準5%で帰無仮説が棄却されたら、帰無仮説の逆の命題（対立仮説と呼ばれる）が消極的に指示されるのである。 6.7 t検定 母分散が未知である場合の一つの平均値の検定 標準正規分布の標本分散を不偏分散で置き換えた以下の推定量 \\[t=\\frac{\\overline{x}-\\mu}{\\hat{\\sigma}/\\sqrt{n}}\\] は自由度\\(n-1\\)の\\(t\\)分布に従うことが知られている。 分散・標準偏差の大きさのイメージで使用したデータが、正規分布しているA大学及びB大学の成績分布の中から抽出されたものだとしよう。例として、 帰無仮説：\\(\\mu=15\\) 対立仮説：\\(\\mu \\neq 15\\) を検定しよう。 #自由度=24のt分布 curve(dt(x,24),-3,3) abline(v=qt(0.025,24)) # 2.5%のライン abline(v=qt(0.975,24)) # 97.5%のライン # t検定を実施するコマンド t.test(smallV,mu=15) ## ## One Sample t-test ## ## data: smallV ## t = -5, df = 24, p-value = 2e-05 ## alternative hypothesis: true mean is not equal to 15 ## 95 percent confidence interval: ## 12 14 ## sample estimates: ## mean of x ## 13 t値が-5.3452であり、2.5%ラインを大きく下回っている。つまり、\\(\\mu=15\\)という帰無仮説が誤っていたと結論づけられる。母平均は15とは言えないという結論が有意水準5%で得られた。 来週以降に行う回帰分析においては、\\(\\mu=0\\)という帰無仮説を検定する。 "],["chapter07.html", "chapter: 7 Rによる重回帰分析 7.1 最小二乗法(Ordinary Least Squere Method)とは 7.2 単回帰の事例 7.3 重回帰分析 7.4 因果推論 (Quasi Experiment)の例", " chapter: 7 Rによる重回帰分析 #install.packages(&quot;gt&quot;) #install.packages(&quot;modelsummary&quot;) # ライブラリコマンドでの読み込みは毎回必要 library(readxl) library(ggplot2) library(dplyr) library(foreign) library(stargazer) library(gt) library(modelsummary) # Macユーザ向けの日本語フォント theme_set(theme_gray(base_size = 10, base_family = &quot;HiraginoSans-W3&quot;)) #ウィンドウズユーザー向けの日本語フォント #windowsFonts(YuGothic = windowsFont(&quot;Yu Gothic&quot;)) #theme_set(theme_gray(base_size = 10, base_family = &quot;YuGothic&quot;)) #getwd() # 現在の作業ディレクトリを確認 setwd(&quot;/users/yamamoto/R/ForTeaching&quot;) # 作業ディレクトリの変更 7.1 最小二乗法(Ordinary Least Squere Method)とは 観測されたデータ\\((X,Y)\\)に対して、 \\[Y=a+bX\\] という直線を当てはめることを考える。データが現実を反映しているとすれば、当てはまりが良ければ良いほど、求められた直線は現実のメカニズムを反映していることになる。もし、完全に当てはまったとすれば問題はないがそのようなことはまずないので、当てはまりの良さを判断する客観的な基準が必要になる。 # courtesy to # https://shohei-doi.github.io/notes/posts/2019-05-17-regression/ n &lt;- 50 tibble(x = rnorm(n, 0, 1), y = x + rnorm(n, 0, 1)) %&gt;% ggplot() + geom_point(aes(x = x, y = y)) + geom_line(aes(x = x, y = x)) + geom_errorbar(aes(x = x, ymin = x, ymax = y),linetype=&quot;dotted&quot;) 上の図でいう垂直方向の直線は試しに引いてみた直線 \\[ \\tilde{Y}=\\tilde{a}+\\tilde{b}x \\] と実際の観測値との誤差を示すものである。この誤差の二乗を最小にするような直線が最も当てはまりの良い直線と考える。誤差を\\(u\\)とすれば、 \\[ \\min J=\\sum \\tilde{u}_i^2=\\sum(Y_i-\\tilde{a}-\\tilde{b}X_i)^2 \\] の解である\\(\\hat{a}\\)と\\(\\hat{b}\\)を最小二乗推定量と呼ぶ。上式を微分してゼロとおくと、 \\[\\frac{\\partial J}{\\partial \\tilde{a}}=\\sum(-2(Y_i-\\hat{a}-\\hat{b}X_i))=0\\] 及び \\[\\frac{\\partial J}{\\partial \\tilde{b}}=\\sum(-2X_i(Y_i-\\hat{a}-\\hat{b}X_i))=0\\] となる。ここで、\\(\\hat{a}\\)と\\(\\hat{b}\\)は上式を満たす傾きと切片として、任意の\\(a\\)と\\(b\\)から区別する意味で使用している。これを変形すると以下を得る。 \\[n\\hat{a}+\\left(\\sum X_i \\right)\\hat{b}=\\sum Y_i\\] 及び \\[ \\left(\\sum X_i \\right)\\hat{a}+\\left(\\sum X_i^2 \\right)\\hat{b}=\\sum X_i Y_i\\] これを連立して解くと、 \\[ \\hat{b}=\\frac{\\sum \\left(X_i - \\overline{X}\\right)\\left(Y_i-\\overline{Y}\\right)}{\\sum \\left(X_i - \\overline{X}\\right)^2}\\] 及び \\[\\hat{a}=\\overline{Y}-\\hat{b} \\overline{X} \\] ただし、\\(\\overline{X}\\)と\\(\\overline{Y}\\)は平均値を意味する。 \\(X\\)及び\\(Y\\)は観測値なので、観測値から傾きと切片を計算できることがわかる。また、回帰直線は必ず標本平均を通ることも確認できる。 なお、最小二乗法に必要な仮定やその優れた性質については、 http://www.yuhikaku.co.jp/books/detail/9784641053854 などの入門の計量経済学の本を参照のこと。 7.2 単回帰の事例 # Wooldridge (2016) Introductory Econometrics, Thomson. # の事例より。 ####################################################### # CEOのサラリーは会社のROEでどの程度説明できるか？ ####################################################### # # 自己資本利益率（ROE：Return on Equity）とは、自己資本（純資産）に対してどれだけの # 利益が生み出されたのかを示す財務分析の指標 # from Wooldridge(2016, section 2.2) #ceosal1の最後の２文字は、小文字のエルと数字の１なので注意 ceosal1&lt;-read.dta(&quot;http://fmwww.bc.edu/ec-p/data/wooldridge/ceosal1.dta&quot;) ceoresult&lt;-lm(salary~roe,data=ceosal1) summary(ceoresult) ## ## Call: ## lm(formula = salary ~ roe, data = ceosal1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1160 -526 -254 139 13500 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 963.2 213.2 4.52 1.1e-05 *** ## roe 18.5 11.1 1.66 0.098 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1370 on 207 degrees of freedom ## Multiple R-squared: 0.0132, Adjusted R-squared: 0.00842 ## F-statistic: 2.77 on 1 and 207 DF, p-value: 0.0978 plot(ceosal1$roe,ceosal1$salary,ylim=c(0,4000)) abline(ceoresult) ####################################################### # 選挙費用で投票結果はどの程度説明できるか？ ####################################################### # from Wooldridge(2016, section 2.2のexample 2.5) # 1988年のアメリカのとある州における国会議員選挙の結果 # voteAは候補者Aの得票シェア、shareAは候補者Aの選挙運動費のシェア vote1&lt;-read.dta(&quot;http://fmwww.bc.edu/ec-p/data/wooldridge/vote1.dta&quot;) voteAresult&lt;-lm(voteA~shareA,data=vote1) summary(voteAresult) ## ## Call: ## lm(formula = voteA ~ shareA, data = vote1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -16.89 -4.07 -0.17 3.50 29.98 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 26.8125 0.8872 30.2 &lt;2e-16 *** ## shareA 0.4638 0.0145 31.9 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 6.4 on 171 degrees of freedom ## Multiple R-squared: 0.856, Adjusted R-squared: 0.855 ## F-statistic: 1.02e+03 on 1 and 171 DF, p-value: &lt;2e-16 plot(vote1$shareA,vote1$voteA) abline(voteAresult) 上の２つ目の結果で、shareAのt値は31.9でt分布の97.5%よりもはるかに大きな値となっている。そのためめったに起らない事象と位置付けることができる。 この時の事象は帰無仮説：\\(\\hat{b}=0\\)であるから、この帰無仮説を棄却し、\\(X\\)と\\(Y\\)は正の相関関係にあると言える。 7.3 重回帰分析 ####################################################### # 大学の成績は何で説明できるか？ ####################################################### # from Wooldridge(2016, example 4.3) # colGPA: 大学での成績 # hsGPA: 高校での成績 # ACT: 大学入試の際に受ける共通テストの成績 # skipped: １週間の平均講義欠席回数 gpa1&lt;-read.dta(&quot;http://fmwww.bc.edu/ec-p/data/wooldridge/gpa1.dta&quot;) GPAresult&lt;-lm(colGPA~hsGPA+ACT+skipped,data=gpa1) summary(GPAresult) ## ## Call: ## lm(formula = colGPA ~ hsGPA + ACT + skipped, data = gpa1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.8570 -0.2320 -0.0393 0.2482 0.8166 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.3896 0.3316 4.19 5.0e-05 *** ## hsGPA 0.4118 0.0937 4.40 2.2e-05 *** ## ACT 0.0147 0.0106 1.39 0.1658 ## skipped -0.0831 0.0260 -3.20 0.0017 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.33 on 137 degrees of freedom ## Multiple R-squared: 0.234, Adjusted R-squared: 0.217 ## F-statistic: 13.9 on 3 and 137 DF, p-value: 5.65e-08 plot(gpa1$colGPA,gpa1$skipped) 7.4 因果推論 (Quasi Experiment)の例 因果推論の方法として、Wooldridge(2016, Example 13.3)を例にDifference-in-Differencesを解説する。この例は、Kiel and McClain(1995, JEEM)からの抜粋であり、Massachusetts州のNorth Andoverにおいて、焼却炉を建設することで周辺の住宅価値が下がったかどうかをDifference-in-Differencesで分析している。 分析の前提条件として、1978年には焼却炉建設の噂さえなかったが1981年には建設の噂が出回ったという背景がある。 住宅価格(\\(=rprice\\))を、1981年のデータだけを使って焼却炉に近い物件のダミー変数(\\(=nearinc\\))で回帰する。 \\[ rprice=a+b\\times nearinc+u \\] kielmc&lt;-read.dta(&quot;http://fmwww.bc.edu/ec-p/data/wooldridge/kielmc.dta&quot;) # Separate regressions for 1978 and 1981: report coeeficients only coef( lm(rprice~nearinc, data=kielmc, subset=(year==1981)) ) ## (Intercept) nearinc ## 101308 -30688 \\(\\hat{b}=-30,688.7\\)という結果を得る。\\(\\hat{a}\\)は平均的な1981年の住宅価格を意味している。しかし、この結果は焼却炉建設の噂がもたらしたマイナス要因とは言えない。なぜなら、まだ噂がなかった1978年のデータだけで上記の式を回帰しても、\\(\\hat{b}=-18824.37\\)というマイナスの結果となるためである。 kielmc&lt;-read.dta(&quot;http://fmwww.bc.edu/ec-p/data/wooldridge/kielmc.dta&quot;) # Separate regressions for 1978 and 1981: report coeeficients only coef( lm(rprice~nearinc, data=kielmc, subset=(year==1978)) ) ## (Intercept) nearinc ## 82517 -18824 つまり、もともと住宅価格の安い地域に焼却炉の建設が行われたのである。よって、焼却炉立地の影響は、 \\[\\hat{b}_{81}-\\hat{b}_{78}=-30,68.27-(-18,824.37)=-11,863.9\\] と考えるのが自然である。これを差の差の推定量(difference-in-differences estimator)と呼ぶ。なぜなら、 \\[\\hat{b}_{81}-\\hat{b}_{78}=\\left(\\overline{rprice}_{81,n}-\\overline{rprice}_{81,f}\\right)-\\left(\\overline{rprice}_{78,n}-\\overline{rprice}_{78,f}\\right)\\] と書き直せるからである。ここで、添字の\\(n\\)は焼却炉に近い住宅の価格、\\(f\\)は遠い住宅の価格を表している。 実践的には、統計的検定ができるように以下の回帰分析で推定量を計算する。 \\[rprice=a+b_{1} \\cdot y81 + b_{2} \\cdot nearinc + b_{3} \\cdot (y81 \\times nearinc) + u\\] を1978年と1981年の両方のデータを使って推定する。ただし、\\(y81\\)は1981年の住宅価格で1、1978年の住宅価格に対して0をとるダミー変数である。この時、\\(a\\)は1978年の平均住宅価格、\\(b_1\\)は1978年から1981年における住宅価格の変化を意味する。\\(b_2\\)は、焼却炉建設と関係なく、焼却炉周辺地域の住宅価格の他地域との差を表す。最後に、\\(b_3\\)は焼却炉建設の噂による価格変化を表す(=DiD estimator)。 このように、焼却炉建設など政策の影響を受けるサンプルをTreatment groupと呼ぶ。影響を受けないグループをControl groupと言う。因果推論を行うためには、Treatment groupとControl groupの両方が必ず必要である。より一般には以下のように書ける。 \\[Y=a+b_{1} \\cdot YD + b_{2} \\cdot T + b_{3} \\cdot (YD \\times T) +\\mathbf{z}+ u\\] ここで、\\(YD\\)はtreatmentの前と後でそれぞれ\\(0\\)と\\(1\\)をとるダミー変数、\\(T\\)はtreatmentのあるなしでそれぞれ\\(1\\)や\\(0\\)をとるダミー変数、\\(\\mathbf{z}\\)はその他の変数をさす。DiD estimatorはもちろん\\(b_3\\)である。 Before After After - Before Control \\(a\\) \\(a+b_1\\) \\(b_1\\) Treatment \\(a+b_2\\) \\(a+b_1+b_2+b_3\\) \\(b_1+b_3\\) Treatment - Control \\(b_2\\) \\(b_2+b_3\\) \\(b_3\\) 7.4.1 例1 # Joint regression including an interaction term # 他のコントロール変数を含めない場合 result1&lt;- lm(rprice~nearinc+y81+I(nearinc*y81), data=kielmc) summary(result1) ## ## Call: ## lm(formula = rprice ~ nearinc + y81 + I(nearinc * y81), data = kielmc) ## ## Residuals: ## Min 1Q Median 3Q Max ## -60678 -17693 -3031 12483 236307 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 82517 2727 30.26 &lt; 2e-16 *** ## nearinc -18824 4875 -3.86 0.00014 *** ## y81 18790 4050 4.64 5.1e-06 *** ## I(nearinc * y81) -11864 7457 -1.59 0.11259 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 30200 on 317 degrees of freedom ## Multiple R-squared: 0.174, Adjusted R-squared: 0.166 ## F-statistic: 22.3 on 3 and 317 DF, p-value: 4.22e-13 7.4.2 例2 # 住宅の築年数だけ含めた場合 result2&lt;- lm(rprice~nearinc+y81+age+I(age^2)+I(nearinc*y81), data=kielmc) summary(result2) ## ## Call: ## lm(formula = rprice ~ nearinc + y81 + age + I(age^2) + I(nearinc * ## y81), data = kielmc) ## ## Residuals: ## Min 1Q Median 3Q Max ## -79349 -14431 -1711 10069 201486 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 8.91e+04 2.41e+03 37.04 &lt; 2e-16 *** ## nearinc 9.40e+03 4.81e+03 1.95 0.05171 . ## y81 2.13e+04 3.44e+03 6.19 1.9e-09 *** ## age -1.49e+03 1.32e+02 -11.33 &lt; 2e-16 *** ## I(age^2) 8.69e+00 8.48e-01 10.25 &lt; 2e-16 *** ## I(nearinc * y81) -2.19e+04 6.36e+03 -3.45 0.00064 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 25500 on 315 degrees of freedom ## Multiple R-squared: 0.414, Adjusted R-squared: 0.405 ## F-statistic: 44.6 on 5 and 315 DF, p-value: &lt;2e-16 7.4.3 例3 # 他のコントロール変数も含めた場合 result3&lt;- lm(rprice~nearinc+y81+age+I(age^2)+I(nearinc*y81)+intst+ land+area+rooms+baths, data=kielmc) summary(result3) ## ## Call: ## lm(formula = rprice ~ nearinc + y81 + age + I(age^2) + I(nearinc * ## y81) + intst + land + area + rooms + baths, data = kielmc) ## ## Residuals: ## Min 1Q Median 3Q Max ## -76721 -8885 -252 8433 136649 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.38e+04 1.12e+04 1.24 0.2172 ## nearinc 3.78e+03 4.45e+03 0.85 0.3966 ## y81 1.39e+04 2.80e+03 4.98 1.1e-06 *** ## age -7.39e+02 1.31e+02 -5.64 3.8e-08 *** ## I(age^2) 3.45e+00 8.13e-01 4.25 2.9e-05 *** ## I(nearinc * y81) -1.42e+04 4.99e+03 -2.84 0.0048 ** ## intst -5.39e-01 1.96e-01 -2.74 0.0064 ** ## land 1.41e-01 3.11e-02 4.55 7.7e-06 *** ## area 1.81e+01 2.31e+00 7.84 7.2e-14 *** ## rooms 3.30e+03 1.66e+03 1.99 0.0476 * ## baths 6.98e+03 2.58e+03 2.70 0.0073 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 19600 on 310 degrees of freedom ## Multiple R-squared: 0.66, Adjusted R-squared: 0.649 ## F-statistic: 60.2 on 10 and 310 DF, p-value: &lt;2e-16 modelsummaryというパッケージでまとめて表示できる。 DiDresults &lt;-list( &quot;Base&quot; = result1, &quot;With year&quot;=result2, &quot;With all&quot;=result3 ) modelsummary(DiDresults,stars = TRUE) Base With year With all (Intercept) 82517.228*** 89116.535*** 1.4e+04 (2726.910) (2406.051) (1.1e+04) nearinc −18824.370*** 9397.936+ 3.8e+03 (4875.322) (4812.222) (4.5e+03) y81 18790.286*** 21321.042*** 1.4e+04*** (4050.065) (3443.631) (2.8e+03) I(nearinc * y81) −11863.903 −21920.270*** −1.4e+04** (7456.646) (6359.745) (5.0e+03) age −1494.424*** −7.4e+02*** (131.860) (1.3e+02) I(age^2) 8.691*** 3.5e+00*** (0.848) (8.1e−01) intst −5.4e−01** (2.0e−01) land 1.4e−01*** (3.1e−02) area 1.8e+01*** (2.3e+00) rooms 3.3e+03* (1.7e+03) baths 7.0e+03** (2.6e+03) Num.Obs. 321 321 321 R2 0.174 0.414 0.660 R2 Adj. 0.166 0.405 0.649 AIC 7540.5 7434.0 7269.5 BIC 7559.3 7460.4 7314.7 Log.Lik. −3765.229 −3710.001 −3622.729 F 22.251 44.591 60.189 RMSE 30053.88 25303.44 19279.94 + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001 7.4.4 logをとった場合 効果を割合として解釈できる。より当てはまりがよくなる場合もある。 DiD &lt;- lm(log(rprice)~nearinc*y81, data=kielmc) DiDcontr &lt;- lm(log(rprice)~nearinc*y81+age+I(age^2)+log(intst)+ log(land)+log(area)+rooms+baths, data=kielmc) DiDlogresults&lt;-list( &quot;Base (log)&quot;=DiD, &quot;With all (log)&quot; = DiDcontr ) modelsummary(DiDlogresults,stars = TRUE) Base (log) With all (log) (Intercept) 11.285*** 7.652*** (0.031) (0.416) nearinc −0.340*** 0.032 (0.055) (0.047) y81 0.193*** 0.162*** (0.045) (0.028) nearinc × y81 −0.063 −0.132* (0.083) (0.052) age −0.008*** (0.001) I(age^2) 0.000*** (0.000) log(intst) −0.061+ (0.032) log(land) 0.100*** (0.024) log(area) 0.351*** (0.051) rooms 0.047** (0.017) baths 0.094*** (0.028) Num.Obs. 321 321 R2 0.246 0.733 R2 Adj. 0.239 0.724 AIC 7451.2 7132.4 BIC 7470.0 7177.7 Log.Lik. −105.675 60.690 F 34.470 84.915 RMSE 0.34 0.20 + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001 焼却炉立地の噂は13.2％の住宅価格押し下げ効果があったことがわかる。 "],["chapter08.html", "chapter: 8 RによるSNSデータの分析 8.1 Twitterデータの活用 8.2 ワードクラウド 8.3 Googleトレンドの分析", " chapter: 8 RによるSNSデータの分析 以下では、Twitterデータを使ったワードクラウドの作成と、GoogleトレンドのRを使った操作を解説します。 8.1 Twitterデータの活用 Twitterデータの取得・分析をおこないます。分析には、rtweetというpackageを使用します。ワードクラウドを作るための準備として、最初に形態素解析のためのソフトウェアを下記の手順でインストールします（ここは大きな山場です）。 # install.packages(&quot;wordcloud2&quot;) library(ggplot2) library(rtweet) ## ## Attaching package: &#39;rtweet&#39; ## The following object is masked from &#39;package:purrr&#39;: ## ## flatten library(tidytext) library(dplyr) library(RMeCab) library(wordcloud2) library(lubridate) ## ## Attaching package: &#39;lubridate&#39; ## The following object is masked from &#39;package:cowplot&#39;: ## ## stamp ## The following objects are masked from &#39;package:base&#39;: ## ## date, intersect, setdiff, union library(tidyr) library(stringr) # ディレクトリの設定 # ここで指定したディレクトリにtmp_dataというフォルダを事前に作成する。 #setwd(&quot;/Users/yamamoto/R/forTeaching/&quot;) 8.1.1 Mecabのインストール はじめに日本語の形態素解析に必要なMecabというソフトウェアをインストールする。 8.1.2 1. Windowsの場合 Mecabのインストール 最初に MeCabをインストールします。ただし、R-4.2.0 以降、オリジナルのMeCabでは動作しません。ここ https://github.com/ikegami-yukino/mecab/releases から 64bit版MeCabをダウンロードし、辞書として必ずUTF-8を指定してください。また、RMeCabで解析するファイルは UTF-8 で保存してください（WindowsのデフォルトはShift-JISであり、全角文字が含まれるCSVファイルなどもRMeCabに読ませる場合はUTF-8に変更してください）。 RMeCabのインストール MeCab本体がデフォルトとは違うフォルダにインストールされている場合、インストール先（デフォルトだとC:Files）にあるmecabrcをコピーし、自分のホームフォルダ(C::）に、頭にドットを付けた .mecabrc ファイルとして用意する必要があります。その際、dicdir = を編集します。ちなみにデフォルトだとdicdir = C:Files 。 8.1.3 2. Macの場合 MacがIntelかM1チップかを確認する。M1チップのMacに誤ってIntel版のRがインストールされていないかも確認する。 Mecabの本家はここですが、今回はターミナルを立ち上げて以下を実行することで、 Mecab本体および使用する辞書のダウンロードからインストールまでを行います。この方法は、こちらを参考にさせていただきました。 cd ~/Downloads curl -fsSL ‘https://drive.google.com/uc?export=download&amp;id=0B4y35FiV1wh7cENtOXlicTFaRUE’ -o mecab-0.996.tar.gz tar xf mecab-0.996.tar.gz cd mecab-0.996 ./configure –with-charset=utf8 make sudo make install 以上でMeCabのインストールが終了する。 ターミナルから以下を実行する（辞書のインストール） cd ~/Downloads curl -fsSL ‘https://drive.google.com/uc?export=download&amp;id=0B4y35FiV1wh7MWVlSDBCSXZMTXM’ -o mecab-ipadic-2.7.0-20070801.tar.gz tar zvxf mecab-ipadic-2.7.0-20070801.tar.gz tar xf mecab-ipadic-2.7.0-20070801.tar.gz cd mecab-ipadic-2.7.0-20070801 ./configure –with-charset=utf8 make sudo make install 以上でMeCabが使う辞書のインストールが終了する。 以下をターミナルで確認する。 $ mecab すもももももももものうち すもも 名詞,一般,,,,,すもも,スモモ,スモモ も 助詞,係助詞,,,,,も,モ,モ もも 名詞,一般,,,,,もも,モモ,モモ も 助詞,係助詞,,,,,も,モ,モ もも 名詞,一般,,,,,もも,モモ,モモ の 助詞,連体化,,,,,の,ノ,ノ 8.1.4 Twitterでの検索ワード 以下の\\(x\\)に検索したいワードを指定する。 \\(n\\)は入手するtweetの数（ただし、無料版では1週間程度しかさかのぼれない）。 #検索ワード x=&quot;エリザベス女王&quot; # こちらにお世話になりました #https://medium.com/@afrasyab/the-best-way-to-use-r-to-get-twitter-data-56ad122194f rt&lt;-search_tweets(x, n=10000,include_rts = FALSE) 8.2 ワードクラウド ワードクラウドでカウントしたくない記号などを排除する。 # 分析に加えたくない記号などを削除する rt$text &lt;- gsub(&quot;https://.*&quot;, &quot;&quot;, rt$text) rt$text &lt;- gsub(&quot;@&quot;, &quot;&quot;, rt$text) rt$text &lt;- gsub(&quot;RT&quot;, &quot;&quot;, rt$text) rt$text &lt;- gsub(&quot;#&quot;, &quot;&quot;, rt$text) rt$text &lt;- gsub(&quot;\\\\(&quot;, &quot;&quot;, rt$text) rt$text &lt;- gsub(&quot;\\\\)&quot;, &quot;&quot;, rt$text) rt$text &lt;- gsub(&quot;/&quot;, &quot;&quot;, rt$text) rt$text &lt;- gsub(&quot;:&quot;, &quot;&quot;, rt$text) # こちらにお世話になりました # https://note.com/text_tier2718/n/n6b20ccd3cb49 rt$text &lt;- rt$text %&gt;% str_replace_all(pattern = &#39;\\\\p{ASCII}&#39;,replacement = &quot;&quot;) # 記号を消します。 形態素解析を実施 rt_text &lt;- rt$text %&gt;% na.omit() %&gt;% #iconv(from = &quot;UTF-8&quot;, to = &quot;CP932&quot;) %&gt;% # windowsのみEncodeの変更が必要です。 paste(collapse = &quot;&quot;) # テキストを結合 textfile &lt;- tempfile() # 一時ファイルの入れ物を作成 write(rt_text, textfile) # docDFで読むために一時ファイルを作成 cloud &lt;- docDF(textfile, type = 1) #形態素解析を行う際に特定の品詞に絞って抽出 ## file_name = /var/folders/13/9dn0stxj0ms73960hn9c5b9r0000gn/T//RtmpAjqaZH/file32ab4b41ef2d opened ## number of extracted terms = 16408 ## now making a data frame. wait a while! #cloud &lt;- docDF(textfile, type = 1, pos = &quot;名詞&quot;) unlink(textfile) # 一時ファイル消去 cloud &lt;- cloud %&gt;% select(everything(), FREQ = starts_with(&quot;file&quot;)) %&gt;% # 4列目のfile****....という名前が長いためFREQへ変更 arrange(desc(FREQ)) # 消したい不要なワードを設定 exclude_word = c(&quot;する&quot;,&quot;なる&quot;,&quot;やる&quot;,&quot;ある&quot;,&quot;いる&quot;,&quot;-&quot;,&quot;♪&quot;,&quot;エリザベス&quot;,&quot;女王&quot;,x) # 動詞と名詞で良い感じのやつを残す cloud2 &lt;- cloud %&gt;% filter(grepl(pattern = &quot;動詞|名詞&quot;, x = POS1) &amp; !grepl(pattern = &quot;助動詞|代名詞&quot;, x = POS1) &amp; !grepl(pattern = &quot;非自立|接尾|数|代名詞&quot;, x = POS2) ) %&gt;% filter(!TERM %in% exclude_word) 可視化をする。 # Takaoフォント様 https://launchpad.net/takao-fonts cloud2 %&gt;% select(TERM,FREQ) %&gt;% slice(1:100) %&gt;% # 描画する範囲を設定 wordcloud2(fontFamily = &#39;Takao Pゴシック&#39;, color = &quot;random-light&quot;, minRotation = 0, maxRotation = 0, size = 1.2) 8.3 Googleトレンドの分析 社会トレンドを分析できる別の手段として、Googleトレンドがあります。検索数ではなく、相対的な変化を表すものですが、人々の関心の変化を時系列で見る上では非常に参考になります。Googleトレンドは、gtrendsRというpackageで分析することが可能です。 #install.packages(&quot;gtrendsR&quot;) library(gtrendsR) # 以下は、https://skume.net/entry/2021/03/28/023122より #引数について #keyword: Google Trends query キーワードである文字ベクトル。複数のキーワード入力も可。 #geo: queryの地理的な地域を示す文字ベクトル。世界中の場合には、&quot;all&quot;を指定する。 #また上記の国コードなどを使用することで、複数の国・地域を指定できる。 #time: queryの期間を指定する文字列。以下を参照のこと。 #&quot;now 1-H&quot; 最後の1時間 #&quot;now 4-H&quot; 最後の4時間 #&quot;now 1-d&quot; 最後の1日 #&quot;now 7-d&quot; 過去7日間 #&quot;today 1-m&quot; 過去30日間 #&quot;today 3-m&quot; 過去90日 #&quot;today 12-m&quot; 過去12ヶ月 #&quot;today+5-y&quot; 過去5年間(デフォルト) #&quot;all&quot; Google Trends の開始時（2004 年）から #&quot;Y-m-d Y-m-d&quot; 2つの日付の間で指定（例：「2010-01-01 2010-04-03」） trendWB5yrs &lt;- gtrends(keyword = &quot;女子バスケ&quot;, geo = &quot;JP&quot;, #地域 time = &quot;today+5-y&quot;) #期間(例：五年) plot(trendWB5yrs) デフォルトのplot関数では凡例が文字化けするようなので、ggplot2にて描画します。 trendWB7days &lt;- gtrends(keyword = &quot;女子バスケ&quot;, geo = &quot;JP&quot;, #地域 time=&quot;now 7-d&quot;) trendWB7days %&gt;% .$interest_over_time %&gt;% ggplot(aes(x = date, y = hits)) + geom_line(colour = &quot;darkblue&quot;, size = 1.5) + theme_bw(base_family = &quot;HiraKakuPro-W3&quot;)+ ggtitle(&quot;直近１週間の検索数の推移(キーワード：「女子バスケ」)&quot;) 複数キーワードに挑戦してみよう。 search_words&lt;-c(&quot;女子バスケ&quot;, &quot;野球日本代表&quot;) Olympics &lt;- gtrends(keyword = search_words, geo = &quot;JP&quot;, #地域 time=&quot;2021-07-21 2021-08-08&quot;) Olympics %&gt;% .$interest_over_time %&gt;% ggplot(aes(x = date, y = hits, color=keyword)) + geom_line( size = 1.5) + ggtitle(&quot;オリンピック期間中のキーワード検索の推移&quot;) 上記の例では、time=\"2021-07-21 2021-08-08\"というフォーマットで期間を設定している点にも注意しよう。これをみると、日本女子バスケットボール代表の快進撃で検索数が大きく増加していることがわかる。 "],["chapter09.html", "chapter: 9 dplyrによるデータ集計 9.1 はじめに 9.2 パイプ演算子について 9.3 エクセル作業を代替してみる", " chapter: 9 dplyrによるデータ集計 9.1 はじめに データ分析にかかる時間の大半は、分析目的に合わせてデータをキレイに整える段階に費やされます。Rのdplyrというpackageを用いて、少しでも楽にデータ集計を進めるためのコツを学びます。 一定の時間が経過した後に見直しをすると、クリック操作で行った手続きを思い出すことは不可能です。できるだけRの環境の中でデータの整理を行うことでデータ整理自体の時間節約になるだけでなく、dplyrコマンドとして作業を記録しておくことで、過去の自分が何をしたかを思い出す時間も節約することができます。 #install.packages(&quot;dplyr&quot;) library(dplyr) library(ggplot2) head(midwest) ## # A tibble: 6 × 28 ## PID county state area popto…¹ popde…² popwh…³ popbl…⁴ popam…⁵ popas…⁶ popot…⁷ percw…⁸ percb…⁹ perca…˟ perca…˟ ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 561 ADAMS IL 0.052 66090 1271. 63917 1702 98 249 124 96.7 2.58 0.148 0.377 ## 2 562 ALEXAN… IL 0.014 10626 759 7054 3496 19 48 9 66.4 32.9 0.179 0.452 ## 3 563 BOND IL 0.022 14991 681. 14477 429 35 16 34 96.6 2.86 0.233 0.107 ## 4 564 BOONE IL 0.017 30806 1812. 29344 127 46 150 1139 95.3 0.412 0.149 0.487 ## 5 565 BROWN IL 0.018 5836 324. 5264 547 14 5 6 90.2 9.37 0.240 0.0857 ## 6 566 BUREAU IL 0.05 35688 714. 35157 50 65 195 221 98.5 0.140 0.182 0.546 ## # … with 13 more variables: percother &lt;dbl&gt;, popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;, ## # poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;, percchildbelowpovert &lt;dbl&gt;, ## # percadultpoverty &lt;dbl&gt;, percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;, and abbreviated variable ## # names ¹​poptotal, ²​popdensity, ³​popwhite, ⁴​popblack, ⁵​popamerindian, ⁶​popasian, ⁷​popother, ⁸​percwhite, ## # ⁹​percblack, ˟​percamerindan, ˟​percasian 9.2 パイプ演算子について パイプ演算子とは%&gt;%のことで、dplyrを読み込むことで使用できます。パイプ演算子は、パイプの左側のオブジェクトを右側に「流す」ことができます。最初は直感的にわかりにくいかもしれませんが、これによって、以下のようなメリットが生まれます。 集計の途中で無駄なデータフレームを作る必要がない。 コードが簡素化され、見やすくなる。 改行が入るので、コメントを残しやすい。 一方、デメリットとしては、たまにパイプ演算子を使うとうまく機能させられない関数がありますが、入門の段階ではそのような現象はほとんどなく、導入のメリットしかないと思いますので、積極的に活用ですべきと考えます。 # パイプ演算子を用いた場合 midwest %&gt;% ggplot()+geom_histogram(aes(poptotal)) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. # パイプ演算子を用いない場合 ggplot(midwest)+geom_histogram(data=midwest,aes(poptotal)) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. # パイプ演算子で他の演算も行う midwest %&gt;% filter(state==&quot;MI&quot;) %&gt;% # 対象をミシガン州だけに ggplot()+geom_histogram(aes(poptotal)) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. # パイプ演算子を用いないで、他の演算も行う midwestMI&lt;-filter(midwest, state==&quot;MI&quot;) ggplot(midwestMI)+geom_histogram(aes(poptotal)) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 最後の例では結果として２行になり、midwestMIというデータフレームも作成された。 9.3 エクセル作業を代替してみる エクセルでクリックで行う作業をコードで残そう。演習に使うデータとして、総務省統計局による家計調査を使用する。 家計調査は標本調査であり，層化3段抽出法（第1段―市町村，第2段―単位区，第3段―世帯）により世帯を選定している。選定にあたっては特定の世帯が続けて調査の対象にならないように配慮している。市町村の抽出の仕方は次のとおりである。都道府県庁所在市及び政令指定都市については各市を1層とし52層に分けた。その他の人口5万以上の市については直近の国勢調査の結果に基づき，地方，都市階級に分けた後， 人口集中地区人口比率 人口増減率 産業的特色 世帯主の年齢構成 を考慮して74層に分けた。また，人口5万未満の市及び町村は，地方で分けた後，(1)地理的位置（海沿い，山地等），(2)世帯主の年齢構成を用いて，計42層に分けた。このようにして分けられた全国計168層の各層から1市町村ずつ抽出した。 地域 調査市町村数 二人以上の調査世帯数 単身調査世帯数 全国 168 8,076 673 都道府県庁所在市及び大都市 52 5,472 456 人口5万以上の市（上記の市を除く） 74 2,100 175 人口5万未満の市及び町村 42 504 42 library(readxl) #ウェブサイトから直接ダウンロードする場合 url1&lt;-&quot;https://yamamoto-masashi.github.io/DSlec/kakei2000.xlsx&quot; download.file(url1,destfile=&quot;kakei2000.xlsx&quot;) # エクセルファイルの読み込み # sheet=1を変更することで別のシートも読める kakeiDB&lt;-readxl::read_excel(&quot;kakei2000.xlsx&quot;,sheet=1) データベースの列を増減する。mutate()関数で新しい変数を加えることができます。select()関数はデータフレームに維持する変数名を指定して任意の大きさのデータフレームに変更できます。以下の例では変数名に「-」(マイナス)をつけることで指定した変数だけを除外したデータフレームを作成しています。 # 列の追加 kakeiDB %&gt;% dplyr::rowwise() %&gt;% mutate(rSum1920=sum(FY2019, FY2020)) -&gt;kakeiDB head(kakeiDB) ## # A tibble: 6 × 28 ## # Rowwise: ## Category1 Catego…¹ Categ…² Categ…³ Categ…⁴ Categ…⁵ FY2000 FY2001 FY2002 FY2003 FY2004 FY2005 FY2006 FY2007 FY2008 ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 食料 10 穀類 1 米 40256 38293 36593 37256 37294 32896 30967 30679 31230 ## 2 1 食料 10 穀類 2 パン 27512 26358 26750 27189 27610 26253 26559 27096 28220 ## 3 1 食料 10 穀類 3 麺類 18771 18373 18389 18165 18053 16662 16292 16414 17985 ## 4 1 食料 10 穀類 4 他の穀… 4354 4266 4169 4170 4041 4759 4643 4880 5127 ## 5 1 食料 11 魚介類 1 生鮮魚… 67847 65056 64564 60487 57670 56018 55315 55007 52070 ## 6 1 食料 11 魚介類 2 塩干魚… 19876 19360 18741 18009 17293 17165 16955 16859 16671 ## # … with 13 more variables: FY2009 &lt;dbl&gt;, FY2010 &lt;dbl&gt;, FY2011 &lt;dbl&gt;, FY2012 &lt;dbl&gt;, FY2013 &lt;dbl&gt;, FY2014 &lt;dbl&gt;, ## # FY2015 &lt;dbl&gt;, FY2016 &lt;dbl&gt;, FY2017 &lt;dbl&gt;, FY2018 &lt;dbl&gt;, FY2019 &lt;dbl&gt;, FY2020 &lt;dbl&gt;, rSum1920 &lt;dbl&gt;, and ## # abbreviated variable names ¹​Category1J, ²​Category2, ³​Category2J, ⁴​Category3, ⁵​Category3J # 列の削除 kakeiDB %&gt;% select(-rSum1920) -&gt; kakeiDB head(kakeiDB) ## # A tibble: 6 × 27 ## # Rowwise: ## Category1 Catego…¹ Categ…² Categ…³ Categ…⁴ Categ…⁵ FY2000 FY2001 FY2002 FY2003 FY2004 FY2005 FY2006 FY2007 FY2008 ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 食料 10 穀類 1 米 40256 38293 36593 37256 37294 32896 30967 30679 31230 ## 2 1 食料 10 穀類 2 パン 27512 26358 26750 27189 27610 26253 26559 27096 28220 ## 3 1 食料 10 穀類 3 麺類 18771 18373 18389 18165 18053 16662 16292 16414 17985 ## 4 1 食料 10 穀類 4 他の穀… 4354 4266 4169 4170 4041 4759 4643 4880 5127 ## 5 1 食料 11 魚介類 1 生鮮魚… 67847 65056 64564 60487 57670 56018 55315 55007 52070 ## 6 1 食料 11 魚介類 2 塩干魚… 19876 19360 18741 18009 17293 17165 16955 16859 16671 ## # … with 12 more variables: FY2009 &lt;dbl&gt;, FY2010 &lt;dbl&gt;, FY2011 &lt;dbl&gt;, FY2012 &lt;dbl&gt;, FY2013 &lt;dbl&gt;, FY2014 &lt;dbl&gt;, ## # FY2015 &lt;dbl&gt;, FY2016 &lt;dbl&gt;, FY2017 &lt;dbl&gt;, FY2018 &lt;dbl&gt;, FY2019 &lt;dbl&gt;, FY2020 &lt;dbl&gt;, and abbreviated variable ## # names ¹​Category1J, ²​Category2, ³​Category2J, ⁴​Category3, ⁵​Category3J filter()関数を使って条件をつけてデータベースの行を絞り込む。 # 魚介類だけを取り出す kakeiDB %&gt;% filter(Category2==11)-&gt;Cat2_11 print(Cat2_11) ## # A tibble: 4 × 27 ## # Rowwise: ## Category1 Catego…¹ Categ…² Categ…³ Categ…⁴ Categ…⁵ FY2000 FY2001 FY2002 FY2003 FY2004 FY2005 FY2006 FY2007 FY2008 ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 食料 11 魚介類 1 生鮮魚… 67847 65056 64564 60487 57670 56018 55315 55007 52070 ## 2 1 食料 11 魚介類 2 塩干魚… 19876 19360 18741 18009 17293 17165 16955 16859 16671 ## 3 1 食料 11 魚介類 3 魚肉練… 10425 10329 9601 9203 9098 8942 8850 9048 9399 ## 4 1 食料 11 魚介類 4 他の魚… 12720 12345 11847 11198 10957 10915 10823 10850 10453 ## # … with 12 more variables: FY2009 &lt;dbl&gt;, FY2010 &lt;dbl&gt;, FY2011 &lt;dbl&gt;, FY2012 &lt;dbl&gt;, FY2013 &lt;dbl&gt;, FY2014 &lt;dbl&gt;, ## # FY2015 &lt;dbl&gt;, FY2016 &lt;dbl&gt;, FY2017 &lt;dbl&gt;, FY2018 &lt;dbl&gt;, FY2019 &lt;dbl&gt;, FY2020 &lt;dbl&gt;, and abbreviated variable ## # names ¹​Category1J, ²​Category2, ³​Category2J, ⁴​Category3, ⁵​Category3J group_by()関数を使ってグループに分けて計算する。今回はsummarize()関数を使って最大値を計算しています。 #2000年の消費（大分類） kakeiDB %&gt;% group_by(Category1J) %&gt;% summarize(max2000=max(FY2000/1000)) %&gt;% ggplot()+ theme_gray (base_family = &quot;HiraKakuPro-W3&quot;)+ coord_flip()+ geom_bar(aes(x = Category1J, y = max2000), stat = &quot;identity&quot;,fill=&quot;orange&quot;)+ xlab(&quot;&quot;)+ylab(&quot;大分類の最大値(2000年, 単位：千円/年)&quot;)+ ggtitle(&quot;家計調査による消費支出（名目値）&quot;) #2020年の消費（大分類） kakeiDB %&gt;% group_by(Category1J) %&gt;% summarize(max2020=max(FY2020/1000)) %&gt;% ggplot()+ theme_gray (base_family = &quot;HiraKakuPro-W3&quot;)+ coord_flip()+ geom_bar(aes(x = Category1J, y = max2020), stat = &quot;identity&quot;,fill=&quot;lightblue&quot;)+ xlab(&quot;&quot;)+ylab(&quot;大分類の最大値(2020年, 単位：千円/年)&quot;)+ ggtitle(&quot;家計調査による消費支出（名目値）&quot;) 二つ以上のデータベースを結合する #2020年のセリーグの成績 teamnameJ&lt;-c(&quot;巨人&quot;, &quot;阪神&quot;, &quot;中日&quot;,&quot;DeNA&quot;, &quot;広島&quot;, &quot;ヤクルト&quot;) win2020&lt;-c(67,60,56,58,52,41) lose2020&lt;-c(45,53,55,58,56,69) pct2020&lt;-c(0.598,0.531,0.522,0.491,0.481,0.373) Cen2020&lt;-as.data.frame(cbind(teamnameJ,win2020,lose2020,pct2020)) print(Cen2020) ## teamnameJ win2020 lose2020 pct2020 ## 1 巨人 67 45 0.598 ## 2 阪神 60 53 0.531 ## 3 中日 56 55 0.522 ## 4 DeNA 58 58 0.491 ## 5 広島 52 56 0.481 ## 6 ヤクルト 41 69 0.373 #2001年のセリーグの成績 teamnameJ&lt;-c(&quot;ヤクルト&quot;, &quot;巨人&quot;, &quot;DeNA&quot;, &quot;広島&quot;, &quot;中日&quot;,&quot;阪神&quot;) win2001&lt;-c(76,75,69,68,62,57) lose2001&lt;-c(58,63,67,65,74,80) pct2001&lt;-c(0.567,0.543,0.507,0.511,0.456,0.416) Cen2001&lt;-as.data.frame(cbind(teamnameJ,win2001,lose2001,pct2001)) print(Cen2001) ## teamnameJ win2001 lose2001 pct2001 ## 1 ヤクルト 76 58 0.567 ## 2 巨人 75 63 0.543 ## 3 DeNA 69 67 0.507 ## 4 広島 68 65 0.511 ## 5 中日 62 74 0.456 ## 6 阪神 57 80 0.416 # 二つの記録を結合する #left_join(A,B)関数はAにBを結合する Cen20012020&lt;-left_join(Cen2001,Cen2020,by=&quot;teamnameJ&quot;) print(Cen20012020) ## teamnameJ win2001 lose2001 pct2001 win2020 lose2020 pct2020 ## 1 ヤクルト 76 58 0.567 41 69 0.373 ## 2 巨人 75 63 0.543 67 45 0.598 ## 3 DeNA 69 67 0.507 58 58 0.491 ## 4 広島 68 65 0.511 52 56 0.481 ## 5 中日 62 74 0.456 56 55 0.522 ## 6 阪神 57 80 0.416 60 53 0.531 Cen20202001&lt;-left_join(Cen2020,Cen2001,by=&quot;teamnameJ&quot;) print(Cen20202001) ## teamnameJ win2020 lose2020 pct2020 win2001 lose2001 pct2001 ## 1 巨人 67 45 0.598 75 63 0.543 ## 2 阪神 60 53 0.531 57 80 0.416 ## 3 中日 56 55 0.522 62 74 0.456 ## 4 DeNA 58 58 0.491 69 67 0.507 ## 5 広島 52 56 0.481 68 65 0.511 ## 6 ヤクルト 41 69 0.373 76 58 0.567 ``` "],["chapter10.html", "chapter: 10 Rmarkdownの使い方 10.1 Rmarkdownを用いる理由 10.2 Rmarkdownの使い方 10.3 参考資料", " chapter: 10 Rmarkdownの使い方 10.1 Rmarkdownを用いる理由 個人的にデータを分析して楽しむ?場合には特に問題になりませんが、将来、データ分析の結果を仕事で用いることになった場合、その再現性が重要になります。前の学期に作業したエクセルファイルをどうやって作成したか、ファイルそのものを見直しても全く思い出せない、という経験がある人が皆さんの中にもいるかもしれません。個人の学習としてはともかく、ビジネスでこのようなことがおこることは絶対に避けなければなりません。 一定の時間が経過した後も同じ結果を確実に再現できるためには当初の分析段階で適切に記録を残しておくことが重要です。分析過程の記録を残すためのpackageとして、Rmarkdownというものがあります。このRmarkdownを使うことで作成者の記録がとりやすいだけでなく、後でこの記録をみる利用者にとってもわかりやす資料を作ることができます。 10.2 Rmarkdownの使い方 最も簡単にRmarkdownを使う方法は、RStudioのメニューからNew File、R Markdownを選択し、htmlで出力することです。このやり方は講義で画面で説明します。 Rmarkdownを用いることで、htmlの途中にRのコードを簡単に含めることができます。このコードは単にコードを表示するだけでなく、htmlを作成するタイミングで実行して実行結果を含めることができます。このコードを含める部分をチャンクと言います。チャンクで使用できるオプションについてはこちらを参考にしてください。 10.3 参考資料 さらに細かい設定などに興味のある人は以下のサイトを参照してください。 Rmarkdown入門 (by kazutan on web) Rmarkdown入門 (by Jaehyun Song) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
